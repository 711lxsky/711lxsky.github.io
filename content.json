{"meta":{"title":"耳易老师","subtitle":"从此无心爱良夜","description":"Forget ever, embrace now.","author":"711lxsky","url":"http://711lxsky.github.io","root":"/"},"pages":[{"title":"","date":"2024-05-31T07:14:34.659Z","updated":"2024-05-31T07:14:34.659Z","comments":true,"path":"404.html","permalink":"http://711lxsky.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2023-06-28T19:30:30.000Z","updated":"2023-06-28T19:30:30.000Z","comments":false,"path":"about/index.html","permalink":"http://711lxsky.github.io/about/index.html","excerpt":"","text":"欢迎访问我的博客! 我–耳易老师： Web开发 算法爱好者（又菜又爱玩儿） 目前西电在读（苦bi计科🐶） 爱好折腾一些小玩意儿 长期不定时发癫更新，如果有任何问题或意见欢迎评论或联系！😜"},{"title":"所有分类","date":"2023-06-28T19:30:30.000Z","updated":"2023-06-28T19:30:30.000Z","comments":true,"path":"categories/index.html","permalink":"http://711lxsky.github.io/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2023-06-28T19:30:30.000Z","updated":"2023-06-28T19:30:30.000Z","comments":true,"path":"contact/index.html","permalink":"http://711lxsky.github.io/contact/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2024-05-31T07:14:34.675Z","updated":"2024-05-31T07:14:34.675Z","comments":true,"path":"friends/index.html","permalink":"http://711lxsky.github.io/friends/index.html","excerpt":"感谢大家~","text":"感谢大家~ 如果你也想和耳易老师建立友谊，可以随时联系我放置友链😄"},{"title":"所有标签","date":"2023-06-28T19:30:30.000Z","updated":"2023-06-28T19:30:30.000Z","comments":true,"path":"tags/index.html","permalink":"http://711lxsky.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"EasyDB 项目回顾","slug":"blog21","date":"2024-05-31T13:00:00.000Z","updated":"2024-05-31T13:00:00.000Z","comments":true,"path":"2024/05/31/blog21/","link":"","permalink":"http://711lxsky.github.io/2024/05/31/blog21/","excerpt":"","text":"EasyDB 项目回顾 最近为简历头疼死了😐，总感觉之前投的简历没写好，而且挺久没看这个项目了，忽然想起来貌似之前有篇博客说要写篇关于这个项目的文章，好吧，那就回顾回顾正好写写 除了这个轮子项目还有一个微服务直播项目，有空也写写(立Flag小能手)🙃，那个业务上写的挺好的感觉 实现功能 俺就不像简历上的那样逐字逐句斟酌了，简单随随便便写写 列一下 事务持久化 计数缓存框架 日志持久化 + WAL机制 第一检验页面和普通页面 + 可靠数据检测恢复机制 页面索引(比较简陋) 数据共享类和全局统一数据类 MVCC + 2PL + 等待图死锁检测 和基于此的调度序列可串行化 + 读已提交、可重复读事务隔离级别 B+树结构的索引 分词器和SQL解析器 表字段、结构管理器 基于Socket的客户端服务端通信加密机制 小小说明 持久化 这里持久化都是放在文件中去做的，所以每次从持久层读都是做磁盘IO，是比较消耗资源的 计数缓存 于是就弄了个技术缓存框架，存放资源的引用情况，当某个资源释放到了引用为0时就直接写回磁盘文件，框架的意思就是提供静态方法直接使用和抽象方法让子类去实现，所以每个缓存实现类都有从数据源/持久层拿到资源的能力 日志 WAL 日志说的是数据库操作的日志，不是项目的日志，日志中存储的是数据操作的记录，WAL(Write-Ahead Logging)即预写式日志，每次数据修改之前先将修改记录落到日志，同时确保其已经刷新到磁盘，再做真正的数据修改 页面设计 页面设计的是固定大小，然后第一页有个特殊用处是做数据校验，每次启动数据库会先将某个字符串写入第一页的某个位置，然后正常关闭时在另一个位置写入同一条字符串；下一次启动时查看这两处的字符串是否一致，不一致就执行redo重做事务和undo回滚事务 页面索引机制则是将页面划分为40个区间，然后以每个页面的空闲区间数量为关键字存到哈希表中，值则是一个页号列表，每次需要将数据写入页面中就从能够满足空间需求的页号列表中拿出一个页面写入 数据传递管理 因为Java取一个数组的分片时，时拷贝这段分片内存中的数据，所以设计一个数据共享类，数据放在一个字节数组中，每次将这个数据传递，并给使用这个数组不同的模块设置不同的起始、结束位置 并发控制调度序列 版本管理中，抽象出一个记录，每个记录会标识创建、删除本身的事务；再维护活跃事务快照； 针对每个事务，看到的都是某个时间点的数据库版本，记录当时的事务快照，这样MVCC多版本并发控制就可以实现； 再基于两段锁(2PL)协议，读和插入时不用在版本管理模块申请锁，而在记录被修改时删除原记录(标识，非真删)时才强制加锁，事务完成记录修改或者回滚时进行解锁，整个过程中相较于单纯的2PL就降低了阻塞概率； 另外加锁时还会利用等待图法，使用深度优先遍历方法进行环检测，有环就是有死锁，有死锁就会尝试回滚这个尝试加锁的事务 B+树索引 这里实现了B+树结构，当时写的时候感觉挺难搞 非叶子节点存储索引数据，叶子节点存储真实数据，同层节点以链表形式连接，单个节点设置有平衡因子，超过这个因子的2倍时进行分裂操作 SQL解析 先写了个分词器，根据特定语法结构将SQL语句进行分割并向外提供逐个读取的方法，然后解析器就利用分词器和字符串匹配，解析不同类型的语句并返回特殊定义的相应结果 其实按道理应该是使用语法树 + 过滤器 表字段、结构管理器 这里就根据不同类型的语句解析解析结果，调用下层的数据模块、版本模块、事务模块做数据持久化、缓存操作 通信 其实这里使用的就是Java原生的Socket，服务端和客户端各自创建ServerSocket和ClientSocket，然后去做连接，这里也比较简陋简单 整体架构模块 通用模块 AbstractCache 抽象缓存层 SubArray 数据共享层 核心层 TransactionManager（TM）事物管理模块 DataManager（DM）数据管理模块 VersionManager（VM）版本管理模块 IndexManager（IM）索引管理模块 StatementParser（SP）语句解析模块 TableManager（TBM）表管理模块 通信层 Transpoter 数据传输器 Server 服务端 Client 客户端 模块解析 针对每个模块稍稍详细地写了些，贴了些源码，整个项目源码可以直接看仓库 -&gt; EasyDB 缓存框架 这里可能被拷打，缓存策略、实现机制 这里使用的是计数缓存框架，不使用LRU是因为考虑到资源驱逐不可控，而使用计数缓存则可以让上层模块主动释放引用，确保模块中不存在这个资源的引用，再去释放资源 实现机制 1. 成员变量和构造函数： 12345678910111213141516171819202122232425262728 // 缓存数据private final HashMap&lt;Long, T&gt; cacheData;// 缓存中资源引用个数标记private final HashMap&lt;Long, Integer&gt; referenceRecord;// 从数据源/持久区中获取资源的记录情况private final HashMap&lt;Long, Boolean&gt; acquisitionSituation;// 缓存最大资源数private final int maxResourceNum;// 现有缓存资源数量private int cacheCounter;private final Lock lock;public AbstractCache(int maxResourceNum) throws ErrorException &#123; if(maxResourceNum &lt; 0)&#123; Log.logErrorMessage(ErrorMessage.CACHE_RESOURCE_NUMBER_ERROR); &#125; this.maxResourceNum = maxResourceNum; this.cacheData = new HashMap&lt;&gt;(); this.referenceRecord = new HashMap&lt;&gt;(); this.acquisitionSituation = new HashMap&lt;&gt;(); this.lock = new ReentrantLock(); this.cacheCounter = 0;&#125; 其中最大缓存资源数设置为一个配置项 2. 抽象方法： 12345678910111213/** * @Author: 711lxsky * @Description: 当资源不在缓存中时，从数据源加载获取 */protected abstract T getCacheFromDataSourceByKey(long cacheKey) throws ErrorException, WarningException;/** * @Author: 711lxsky * @Description: 释放缓存，并写回文件/磁盘 * 写回一般指的是将脏页数据写入到对应硬盘或者其他持久化存储设备中 */protected abstract void releaseCacheForObject(T Object) throws WarningException, ErrorException; 这两个抽象方法是具体的缓存实现类继承后去做的，分别是从数据源获取数据（类似从磁盘读）和释放缓存时的写回操作（写入持久化文件/磁盘） 3. 操作逻辑： 类中提供两个方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 /** * @Author: 711lxsky * @Description: 获取某个资源，可能是从缓存中拿到，也可能是去获取，然后放入缓存 * 所以这个方法本身也就是在获取缓存数据 */protected T getResource(long key) throws WarningException, ErrorException &#123; while(true)&#123; this.lock.lock(); // 如果请求的资源一直在被其他线程获取，就反复等待尝试 if(this.acquisitionSituation.containsKey(key))&#123; this.lock.unlock(); try &#123; Thread.sleep(ThreadSetting.CACHE_GET_SLEEP_TIME); &#125; catch (InterruptedException e) &#123; Log.logWarningMessage(e.getMessage()); continue; &#125; continue; &#125; // 如果资源在缓存中，直接返回 if(this.cacheData.containsKey(key))&#123; T object = this.cacheData.get(key); // 拿到资源，给引用数+1 this.referenceRecord.put(key, this.referenceRecord.get(key) + 1); this.lock.unlock(); return object; &#125; // 尝试获取该资源并放入缓存 if(this.maxResourceNum &gt; 0 &amp;&amp; this.cacheCounter == this.maxResourceNum)&#123; // 缓存已经满了 this.lock.unlock(); Log.logWarningMessage(WarningMessage.CACHE_FULL); return null; &#125; // 缓存没满，在资源获取中注册一下，准备从数据源获取资源 this.acquisitionSituation.put(key, true); this.lock.unlock(); break; &#125; this.lock.lock(); T object; try &#123; object = this.getCacheFromDataSourceByKey(key); this.cacheData.put(key, object); this.cacheCounter ++; this.referenceRecord.put(key, 1); this.acquisitionSituation.remove(key); &#125; finally &#123; this.lock.unlock(); &#125; return object;&#125; /** * @Author: 711lxsky * @Description: 释放一个资源引用 */protected void releaseOneReference(long key) throws WarningException, ErrorException &#123; this.lock.lock(); try &#123; // 把引用数 - 1 int referenceNum = this.referenceRecord.get(key) - 1; // 如果接下来资源没有被引用，就释放写回 if(referenceNum == 0)&#123; T obj = cacheData.get(key); this.releaseCacheForObject(obj); this.referenceRecord.remove(key); this.cacheData.remove(key); this.cacheCounter --; &#125; else &#123; this.referenceRecord.put(key, referenceNum); &#125; &#125; finally &#123; this.lock.unlock(); &#125;&#125; getResource()方法先在一个while循环中不断申请资源，如果在资源获取情况记录表中别的资源正在从数据源拿到这个资源就让线程sleep，直到没有其他线程获取这个资源，然后如果缓存就在缓存资源表中就直接拿到返回，同时将引用次数 + 1；如果不在其中，就先判断是否达到最大缓存数量，再在资源获取表中注册一下，调用实现类的获取资源方法，跳出循环，如果获取成功就放入缓存。 releaseOneReference()方法释放资源引用时，先将引用表中的引用数 - 1，如果降到0了，说明这个资源没有被引用，可以被释放了，就调用实现类的释放资源写回持久区的方法，同时移除删除这个缓存 这两个方法执行的过程中都有加解锁操作，就是为了保证线程安全，缓存资源数据不会出现紊乱 4. 安全关闭 此外，还有一个安全关闭策略，用于缓存关闭时强制将资源全部写回持久区 12345678910111213141516171819/** * @Author: 711lxsky * @Description: 安全关闭缓存，并将资源数据写回 */ protected void close() throws ErrorException, WarningException &#123; this.lock.lock(); try&#123; Set&lt;Long&gt; keys = this.cacheData.keySet(); for(long key: keys)&#123; T obj = this.cacheData.get(key); this.releaseCacheForObject(obj); this.cacheData.remove(key); this.referenceRecord.remove(key); &#125; &#125; finally &#123; this.lock.unlock(); &#125; &#125; SubArray 数据共享层 因为Java中数组分片截取时，是做一个元素复制，而不是指向同一片内存，所以针对截取部分数组的修改对原数组不可见，这里封装了一个类： 1234567891011121314151617public class SubArray &#123; // 原始数据 public byte[] rawData; // 数据开始位置标记 public int start; // 数据结束位置标记 public int end; public SubArray(byte[] rawData, int start, int end) &#123; this.rawData = rawData; this.start = start; this.end = end; &#125;&#125; 传递类实例的时候，对数据进行修改了可以感知到 TransactionManager（TM） 概述 作为事物管理模块，以XID为第一关键字，将所有事务信息持久化在.xid文件中。并提供接口供其他模块查询某个事务的状态 事务状态 设为全局常量，放在一个常量配置类中，有三种: 1234// 事务状态，正在执行，已提交，已撤销 public static final byte TRANSACTION_ACTIVE = 0; public static final byte TRANSACTION_COMMITTED = 1; public static final byte TRANSACTION_ABORTED = 2; 特殊 提供一个超级事务，这个事务的XID为0，可以在没有申请的事务的情况下执行某些操作。且超级事务状态永远是committed TM模块只负责记录、维护某个事务状态，涉及事务数据提交、回滚另有数据管理模块做 .xid文件结构 每个事务都有一个XID，这个XID唯一标识此事务，且XID从1开始自增，不可重复（相对单个的.xid文件而言，如果不在同一个文件自然可以重复）。 文件头部有一个8字节大小的数字，记录当前文件中的事务数量，然后每个事务的状态占据1个字节 所以结构是这样： [t_cnt 事务个数(8字节)][t_status 事务状态(1字节)]… 某个XID = x_id的事务状态存储在(x_id - 1) + 8字节位置(XID=0的超级事务不需记录) 提供接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * @Author: 711lxsky * @Description: 开启新事务 */long begin() throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 提交新事务 */void commit(long xid) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 取消事务 */void abort(long xid) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 查询某个事务状态是否为活动状态 */boolean isActive(long xid) throws ErrorException;/** * @Author: 711lxsky * @Description: 查询某个事务状态是否为已提交状态 */boolean isCommitted(long xid) throws ErrorException;/** * @Author: 711lxsky * @Description: 查询某个事务状态是否为已回滚状态 */boolean isAborted(long xid) throws ErrorException;/** * @Author: 711lxsky * @Description: 关闭事务管理器 */void close() throws ErrorException;/** * @Author: 711lxsky * @Description: 根据某个路径创建一个新的事务管理器 */ static TransactionManagerImpl create(String xidFileFullName) throws WarningException, ErrorException &#123; // 创建基础文件 File newFile = FileManager.createFile(xidFileFullName + TMSetting.XID_FILE_SUFFIX); return buildTMWithFile(newFile, false);&#125; /** * @Author: 711lxsky * @Description: 根据某个路径打开一个事务管理器 */static TransactionManagerImpl open(String xidFileFullName) throws WarningException, ErrorException &#123; // 创建基础文件 File newFile = FileManager.openFile(xidFileFullName + TMSetting.XID_FILE_SUFFIX); return buildTMWithFile(newFile, true);&#125; 实现逻辑要点 这里可能是面试拷打点，NIO、文件 .xid文件类型和读取 .xid文件使用的类型使用的是RandomAccessFile，文件读写基于从其中拿到的FileChannel 首先，RandomAccessFile提供文件的随机访问能力，允许程序直接跳转到文件的任意位置进行读写操作。 其次，FileChannel是Java NIO的一部分，支持直接缓冲区和内存映射文件，这允许操作系统在不涉及Java堆的情况下处理大文件，减少数据拷贝，提高性能；另外还提供文件锁定功能，实现文件或文件区域的独占访问，在多线程环境下保证数据一致性 计数器校验 打开.xid文件并创建一个TransactionManager实现类实例时，会校验.xid文件头，先是看文件长度会不会小于计数器长度，然后根据计数器算出事务数量以及相应需要的文件长度，和实际文件长度对比 计数器操作 实现类中有一个锁成员变量，用以在修改计数器时进行加解锁操作，防止其他线程修改，造成数据不一致 接口实现 begin(): 先将计数器 + 1 位置的事务状态设置为执行中，再自增计数器 close(): 关闭RandomAccessFile和FileChannel 其他方法就是根据XID从相应位置读出状态或者更新状态 or 加以判断(中间包含校验超级事务逻辑) DM 数据管理模块 DM模块管理数据库DB文件和日志文件。 主要职责： 分页管理DB文件，并缓存 管理日志文件，保证在发生错误时可以根据日志进行恢复 抽象DB文件为DataItem供上层模块调用 所以，DM模块是上层模块和文件系统至之间的抽象层，向下读写文件，向上提供数据包装，再加上一个日志功能 对外提供接口 1234567891011121314151617181920212223242526272829/** * @Author: 711lxsky * @Description: 以DataItem形式读取并返回数据 */DataItem readDataItem(long uid) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 插入数据，先包裹成DataRecord格式，然后再借助页面索引插入到相应的页中，返回uid */long insertData(long xid, byte[] data) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 调用Logger的writeLog方法，将日志写入到日志文件中 */void writeLog(byte[] log) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 释放一个DataItem对象 */void releaseOneDataItem(long uid) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 关闭相应的资源 */void close() throws ErrorException, WarningException; 除了这些，还有create()和open()方法，前者会调用PageCache和Logger进行相应文件创建，后者则是打开并校验数据 实现逻辑 页面 针对文件系统，将其抽象成为页面，每次对文件系统的读写都是以页面为单位，且这里将单个页面的大小设置为8KB，放在配置类中，可修改 页面缓存 有一个页面缓存的实现，这个缓存对外提供接口： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @Author: 711lxsky * @Description: 拿到数据库文件中的页数，表示有多少个页面 */int getPagesNumber();/** * @Author: 711lxsky * @Description: 新建一个页面到数据库文件，并放入需要存放的数据，返回页号 * 这里并没有自动放到缓存里 */int buildNewPageWithData(byte[] initData) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 根据页号，从缓存中获取页面 */Page getPageByPageNumber(int pageNumber) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 释放一个页面资源引用 */void releaseOneReference(Page page) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 这个方法是用来恢复数据或者其他场景下，截断页面文件 */void truncatePageWithMPageNum(int maxPageNumber) throws WarningException;/** * @Author: 711lxsky * @Description: 刷新页面缓存到文件中 */void flushPage(Page page) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 关闭页面缓存，这里是基于RandomAccessFile实现，需要关闭资源 */void close() throws ErrorException; 同时类似于TM，会创建或者打开一个.pg文件，用以做页面数据的持久化，不同的是加入了一个long类型的memory内存大小参数，用以计算数据页资源的最大缓存数量 实现类中，成员变量有： 1234567891011121314151617181920/** * 页面数据文件 */ private final RandomAccessFile pageDataFile; /** * 数据文件通道 */ private final FileChannel pageFileChannel; /** * 记录当前打开的页面数据文件所含页面的页数， * 此数据在打开时就会被计算，并在创建页面时自增 */ private final AtomicInteger pageNumbers; /** * 放锁，防止多个线程同时操作文件造成数据不一致 */ private final Lock pageFileLock; 所以新建一个页面时，就自增原子数据，然后将数据包裹为通用Page对象，写入刷新到.pg文件中 前面说了单个页面数据的大小，所以需要拿到某个页面的数据时，偏移量就是 (long) (pageNumber - 1) * PageSetting.PAGE_SIZE; 至于从数据源拿到缓存资源，这里的key就是页面号，算到偏移量之后直接读数据；释放资源写回文件操作是，判断这个page是否是脏页，是的话就写回 截断页面方法，是为了为恢复数据作铺垫，直接将.pg文件截断到某个长度 页面对象 这里首先有一个通用的页面接口Page 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @Author: 711lxsky * @Description: 加锁，或者这个页面读写的时候上锁，保证数据一致性 */ void lock(); /** * @Author: 711lxsky * @Description: 释放锁 */ void unlock(); /** * @Author: 711lxsky * @Description: 释放页面缓存 */ void releaseOneReference() throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 设置页面数据的脏标记 */ void setDirtyStatus(Boolean status); /** * @Author: 711lxsky * @Description: 判断页面是不是脏数据 */ boolean isDirty(); /** * @Author: 711lxsky * @Description: 获取页面的页号 */ int getPageNumber(); /** * @Author: 711lxsky * @Description: 获取页面数据的字节形式的原始数据 */ byte[] getPageData(); 落到实现类上去也很简单，成员变量： 12345678910111213141516171819202122232425/** * 页面页号，从 1 开始 */ private final int pageNumber; /** * 页面包含的字节数组形式数据 */ private final byte[] data; /** * 脏状态标记 * 脏的话意味着缓存中的数据和内存/持久层中的数据不一致，缓存驱逐时务必写回 */ private boolean dirtyStatus; /** * 页面缓存 */ private final PageCache pageCache; /** * 页面锁，资源控制 */ private final Lock lock; 唯一需要注意的就是PageCache的使用，释放一个资源时，就是释放本身 其次是第一页，这个页面用以做数据库启动时的数据校验，DB启动时，给100~107字节处填入一个随机字节ValidCheck，DB关闭时再将其拷贝到108～115字节处（这个位置可调）， 数据库每次启动时，会检查两处字节是否相同，以此判断上一次是否正常关闭。如果非正常关闭，就需要执行数据恢复 再就是普通页，这个页在文件中的结构是 [页头][存储数据] 页头是个2字节的无符号整形，记录了当前页的空闲空间的偏移量 此类就提供一些数据修改的方法 注意： 第一页和普通页提供的都是静态方法，数据都是持久化在.pg文件中的，是由通用Page控制的 日志 对外提供接口 1234567891011121314151617181920212223242526272829/** * @Author: 711lxsky * @Description: 写入日志 */ void writeLog(byte[] data) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 定位指针到日志数据起始位置 */ void rewind(); /** * @Author: 711lxsky * @Description: 读取下一条日志信息 */ byte [] readNextLogData() throws ErrorException, WarningException; /** * @Author: 711lxsky * @Description: 截断日志文件到指定长度 */ void truncate(long length) throws WarningException; /** * @Author: 711lxsky * @Description: 关闭日志 */ void close() throws ErrorException; 持久化也是基于一个.log文件 具体实现 实现类的成员变量： 1234567891011121314151617181920212223242526272829/** * 日志文件 */ private final RandomAccessFile logFile; /** * 日志文件通道 */ private final FileChannel logFileChannel; /** * 资源锁 */ private final Lock lock; /** * 日志文件位置指针 */ private long logFileLocationPointer; /** * 日志文件原始长度，读取日志的时候不去改动 */ private long logFileOriginLength; /** * 日志文件总校验和 */ private int logsChecksum; 日志文件的格式： [LogsChecksum] [Log1] [Log2] … [LogN] [BadTail] LogsChecksum为后续所有日志计算的Checksum，4字节int类型 Log1...LogN是常规日志数据 BadTail是在数据库崩溃时，没有来得及写完的日志数据，这个BadTail不一定存在 单条日志记录格式： [Size][Checksum][Data] Size标记Data字段的字节数, 4字节int类型 Checksum是该条数据的校验和， 4字节int类型 Data是实际的数据 日志数据类型分为插入和更新，没有删除是因为直接将这条数据的有效标志位设为invalidate即可 单条日志的校验和基于一个种子算出： 12345678910/** * @Author: 711lxsky * @Description: 根据种子计算校验和 */ private int calculateChecksum(int logChecksum, byte[] log)&#123; for(byte littleData : log)&#123; logChecksum = logChecksum * LoggerSetting.LOGGER_SEED + littleData; &#125; return logChecksum; &#125; 实现类有一个用于读取下一条日志的方法，可以为其他模块提供迭代读取日志数据的功能 另外还提供一个截断方法，将FileChannel截断到指定位置 恢复策略 有一个Recover类，专门用于进行数据恢复 调用日志模块，迭代读取每条日志，并拿到最大的事务xid，以此xid为基准，截断页面文件，再从前到后顺序redo重做所有状态不是活跃（也就是已提交和撤销）的事务；从后到前undo逆序回滚所有未完成（也就是活跃）的事务 页面索引 页面空间在页面索引管理视角下，是被分割成40个(默认，可调)小区间的， 初始时空闲区间数量就是40, 然后用着用着就会减少空间，空闲区间数量会减少 所以页面索引就以空闲区间的数量为基准，管理页面，每次写一个页面时，就会按照需要的空间大小去找合适的页面 在启动时，就会遍历所有的页面信息，获取页面的空闲空间，安排到这40个区间中 insert在请求一个页时，会首先将所需的空间向上取整，映射到某一个区间，随后取出这个区间的任何一页，都可以满足需求 实现的逻辑是在能满足空间要求的情况下，优先去找空闲空间更小的页面 注意：插入时被选择的页会被直接从PageIndex中暂时移除，上层模块调用完之后再重新插入 DataItem DM层向上提供的数据抽象接口，上层模块通过地址，向DM请求到相应的DataItem,再获取数据 DataItem中保存的数据结构DataRecord格式： [Valid][DataSize][Data] Valid: 1字节, 用于标记数据是否有效，1有效， 0无效 DataSize: 2字节， 标识Data的大小 提供接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118/** * @Author: 711lxsky * @Description: 获取DataRecord数据记录，非完整原始数据 */ SubArray getDataRecord(); /** * @Author: 711lxsky * @Description: 获取完整原始数据记录 */ SubArray getRawDataRecord(); /** * @Author: 711lxsky * @Description: 检查数据是否有效 */ boolean isValid(); /** * @Author: 711lxsky * @Description: 在修改数据之前进行的操作 */ void beforeModify(); /** * @Author: 711lxsky * @Description: 撤销修改操作 */ void unBeforeModify(); /** * @Author: 711lxsky * @Description: 数据修改之后的操作 */ void afterModify(long xid) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 释放一个引用 */ void releaseOneReference() throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 读锁申请 */ void readLock(); /** * @Author: 711lxsky * @Description: 读锁释放 */ void readUnlock(); /** * @Author: 711lxsky * @Description: 写锁申请 */ void writeLock(); /** * @Author: 711lxsky * @Description: 写锁释放 */ void writeUnlock(); /** * @Author: 711lxsky * @Description: 拿到数据页 */ Page getPage(); /** * @Author: 711lxsky * @Description: 获取DataItem的唯一标识 */ long getUid(); /** * @Author: 711lxsky * @Description: 获取原始数据记录 */ byte[] getOldDataRecord(); /** * @Author: 711lxsky * @Description: 包裹Data构建DataRecord */ static byte[] buildDataRecord(byte[] data)&#123; byte[] valid = new byte[]&#123;DataItemSetting.DATA_VALID&#125;; byte[] size = ByteParser.shortToBytes((short)data.length); return Bytes.concat(valid, size, data); &#125; /** * @Author: 711lxsky * @Description: 构建DataItem */ static DataItem buildDataItem(Page page, short offset, DataManager dm)&#123; byte[] rawData = page.getPageData(); // 注意这里是获取DataARecord中的DataSize byte[] dataItemDataSizeBytes = Arrays.copyOfRange(rawData, offset + DataItemSetting.DATA_SIZE_OFFSET, offset + DataItemSetting.DATA_DATA_OFFSET); short dataItemDataSize = ByteParser.parseBytesToShort(dataItemDataSizeBytes); // 得到整个DataRecord的大小 short dataRecordLength = (short)(DataItemSetting.DATA_DATA_OFFSET + dataItemDataSize); long uid = Logger.parsePageNumberAndOffsetToUid(page.getPageNumber(), offset); // 转换成SubArray的形式进行构建DataItem SubArray dataRecord = new SubArray(rawData, offset, offset + dataRecordLength); return new DataItemImpl(dataRecord, new byte[dataRecordLength], page, uid, dm); &#125; /** * @Author: 711lxsky * @Description: 设置DataRecord为无效 */ static void setDataRecordInvalid(byte[] dataRecord)&#123; dataRecord[DataItemSetting.DATA_VALID_OFFSET] = DataItemSetting.DATA_INVALID; &#125; 上层模块需要对DataItem进行修改操作时，需要先调用beforeModify()方法，然后修改数据，最后调用afterModify()方法将记录写入日志；如果要撤销修改，就调用unBeforeModify()方法，将备份数据拷回 另外，与之相关的缓存键是由页号和偏移量组成的8 字节无符号整数 VersionManager 版本控制模块 这里被拷打的几率很大，并发控制，调度序列，事务隔离级别 VM模块是事务额数据版本的管理核心 实现MVCC多版本并发控制 DM向外提供DataItem，而VM通过管理所有数据项，向上层提供记录，上层模块操作数据的最小单位就是记录，然后VM在内部为每个记录维护了多个版本，每当上层模块对某个记录进行修改时，VM就会为这个记录创建一个新版本 采用两段锁协议2PL实现调度序列的可串行化，同时利用MVCC降低事务阻塞概率 实现事务隔离级别的读已提交和可重复读 事务抽象 针对事务操作，实现一个事务类 成员变量 1234567891011// 抽象事务的XID private long xid; // 事务隔离级别 private final int transactionIsolationLevel; // 当前事务执行(开始)时的活跃事务XID快照集合 private Set&lt;Long&gt; snapshotXIDsForActiveTransaction; // 意外终止标志，后续出现问题，这个成员变量会被设置为true，表示事务选择中止 private boolean accidentalTermination; snapshotXIDsForActiveTransaction是专门用以记录某个事务执行时活跃的事务xid，方便可重复读级别下进行判断某个事务是否在当前事务的快照中 同时还有一个事务意外终止判断，如果发生意外终止就将此成员变量设为true 记录Record 这个类用以维护记录结构，且一个这个对象只有一个版本，一条记录存储在一个DataItem中 结构 [XMIN][XMAX][Data] XMIN表示的是创建这个记录的事务XID,也就是在此事务之后的事务才有可能拿到这个记录 XMAX表示的是删除这个记录的事务XID,也就是在此事务之前的事务才有可能拿到这个记录,前两者都是8字节long Data是这个事务持有的数据 逻辑操作 数据读取时，需要获取读锁 修改数据XMAX时，需要调用DataItem的方法 这里只有一个构建方法，用以根据xid和data包裹成一个Record字节数组数据，然后就是设置XMAX方法，data数据修改逻辑交给TBM管理 事务可见性判断 这里有一个类VisibilityJudge实现了针对读已提交和可重复读的事务可见性判读 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * @Author: 711lxsky * @Description: 针对特定事务隔离级别，判断记录对事务是否可见 */public static boolean judgeVisibility(TransactionManager tm, Transaction transaction, Record record) throws WarningException, ErrorException &#123; long transactionXid = transaction.getXid(); long recordXmin = record.getXMIN(); long recordXmax = record.getXMAX(); // 记录由当前事务创建且未被删除，可见 if(transactionXid == recordXmin &amp;&amp; recordXmax == VMSetting.RECORD_XMAX_DEFAULT) &#123; return true; &#125; switch (transaction.getTransactionIsolationLevel())&#123; case VMSetting.TRANSACTION_ISOLATION_LEVEL_READ_COMMITTED: return judgeForReadCommitted(tm, recordXmin, recordXmax); case VMSetting.TRANSACTION_ISOLATION_LEVEL_REPEATABLE_READ: return judgeForRepeatableRead(tm, transaction, recordXmin, recordXmax); default: Log.logWarningMessage(WarningMessage.TRANSACTION_ISOLATION_LEVEL_UNKNOWN); return false; &#125;&#125;/** * @Author: 711lxsky * @Description: 读已提交级别判断 */private static boolean judgeForReadCommitted(TransactionManager tm, long recordXmin, long recordXmax) throws ErrorException &#123; // 如果记录由某个已经提交的事务创建 if(tm.isCommitted(recordXmax))&#123; // 如果还未被删除，则可见 if(recordXmax == VMSetting.RECORD_XMAX_DEFAULT)&#123; return true; &#125; // 如果记录已被删除，则判断删除事务是否已经提交 // 未提交则可见， 已提交则不可见 if(recordXmax != recordXmin)&#123; return ! tm.isCommitted(recordXmax); &#125; &#125; // 其他情况不可见 return false;&#125;/** * @Author: 711lxsky * @Description: 重复读级别判断 */private static boolean judgeForRepeatableRead(TransactionManager tm, Transaction transaction, long recordXmin, long recordXmax) throws ErrorException &#123; long transactionXid = transaction.getXid(); // 如果记录由某个已经提交的事务创建，且该事务在当前事务执行之前提交 if(tm.isCommitted(recordXmin) &amp;&amp; (recordXmin &lt; transactionXid &amp;&amp; !transaction.isInSnapshot(recordXmin)))&#123; // 未被删除，可见 if(recordXmax == VMSetting.RECORD_XMAX_DEFAULT)&#123; return true; &#125; // 被删除，则判断删除事务是否已经提交，或者在当前事务执行之后执行/提交 if(recordXmax != recordXmin)&#123; return ! tm.isCommitted(recordXmax) || recordXmax &gt; transactionXid || transaction.isInSnapshot(recordXmax); &#125; &#125; // 其他情况不可见 return false;&#125; 读已提交的问题： 不可重复读和幻读 不可重复读（Non-repeatable Read）： 发生在同一个事务内，当事务在不同时间点读取相同数据时，由于其他事务对数据的更新（修改或删除），导致事务内部的两次读取结果不一致。 例子：假设事务A读取一行记录，然后事务B更新了该记录并提交，事务A再次读取同一行时，会发现数据已被修改，尽管事务A自己没有进行任何写操作。 幻读（Phantom Read）： 也是在同一个事务内，当事务执行两次相同的查询（比如范围查询），由于其他事务在两次查询之间插入了新的记录，使得第二次查询的结果包含了第一次查询时不存在的记录。 例子：事务A首次执行一个区间查询，得到一定范围内的记录。随后，事务B在该范围内插入新的记录并提交，事务A再次执行相同的查询，会发现新的记录出现在结果集中，仿佛是“幻影”般突然出现。 不可重复读关注的是数据行本身的修改，即数据值的变更，而幻读关注的是数据集的完整性，即在查询范围内行数的增减 在此基础上，可重复读需要忽略：在当前事务之后开始的事务数据、本事务开始时还是active状态事务的数据 版本跳跃问题：事务读取数据时跳过了某些版本，实际上问题不是很大，中间事务的修改看不到了而已，最终保存的是最后事务的提交结果 读已提交允许版本跳跃，可重复读不允许 解决版本跳跃： 如果当前事务Ti需要修改某个数据X，但是X已经被当前事务Tj不可见的事务修改，那么就要求Tj回滚。至于不可见的条件，就是Tj在Ti之后执行且已提交或者Tj在Ti的快照中（Ti开始时Tj活跃） 1234567891011/** * @Author: 711lxsky * @Description: 判断记录是否出现版本跳跃 */ public static boolean judgeVersionHopping(TransactionManager tm, Transaction transaction, Record record) throws ErrorException &#123; if(transaction.getTransactionIsolationLevel() == VMSetting.TRANSACTION_ISOLATION_LEVEL_READ_COMMITTED)&#123; return false; &#125; long recordXmax = record.getXMAX(); return tm.isCommitted(recordXmax) &amp;&amp; (recordXmax &gt; transaction.getXid() || transaction.isInSnapshot(recordXmax)); &#125; 死锁检测 因为2PL会阻塞事务，直到持有锁的线程释放锁。为了检测死锁，可以将锁的等待关系抽象成有向边，查看这个图中是否存在环 VersionLockManager 这里实现了一个VersionLockManager类，用以在内存中维护图 每次出现等待时，就尝试向图中增加一条边，并进行死锁检测，如果检测死锁就撤销这条边，不允许添加，并撤销事务 成员变量 1234567891011121314151617181920212223242526272829/** * 某个XID事务已经控制的Record记录列表， 一个XID事务可以控制多个Record记录 */ private final Map&lt;Long, List&lt;Long&gt;&gt; transactionControlledRecords; /** * 某个Record记录被哪个XID事务持有，一个Record记录只能被一个XID事务持有 */ private final Map&lt;Long, Long&gt; recordControlledByTransaction; /** * 等待获取某个Record记录的XID事务列表，一个Record记录可以被多个XID事务等待 */ private final Map&lt;Long, List&lt;Long&gt;&gt; recordWaitByTransactions; /** * 某个XID事务，在等待获取目标Record记录， 一个XID事务只能等待一个Record记录 */ private final Map&lt;Long, Long&gt; transactionWaitForRecord; /** * 正在等待资源的XID事务，携带锁 */ private final Map&lt;Long, Lock&gt; transactionWaitWithLock; /** * 内部进程资源锁 */ private final Lock selfLock; 逻辑设计 此类中有一个方法，尝试获取记录资源，如果资源没有被任何事务持久则在成员变量表中注册一下，返回null；如果已经被持有，将当前事务xid放入一个等待队列中，返回一个ReentrantLock锁 死锁检测方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * @Author: 711lxsky * @Description: 死锁检测 */ private boolean detectDeadlock() throws ErrorException &#123; this.transactionStamp = new HashMap&lt;&gt;(); this.stampMark = VMSetting.VERSION_LOCK_DEADLOCK_DETECT_RING_STAMP_DEFAULT; // 从已经获取资源的事务中寻找 for(long transactionXid : this.transactionControlledRecords.keySet())&#123; // 当前事务戳 Integer xidStamp = this.transactionStamp.get(transactionXid); // 该事务已经被标记过，跳过检测 if(Objects.nonNull(xidStamp) &amp;&amp; xidStamp &gt; VMSetting.VERSION_LOCK_DEADLOCK_DETECT_RING_STAMP_DEFAULT)&#123; continue; &#125; // 自增，dfs测环 this.stampMark ++; if(this.deepFirstSearchForDeadLock(transactionXid))&#123; return true; &#125; &#125; return false; &#125; /** * @Author: 711lxsky * @Description: 深度优先搜索检测死锁 */ private boolean deepFirstSearchForDeadLock(long searchXid) throws ErrorException &#123; Integer searchXidStamp = this.transactionStamp.get(searchXid); // 存在环，有死锁 if(Objects.nonNull(searchXidStamp) &amp;&amp; searchXidStamp == this.stampMark)&#123; return true; &#125; // 已经被检查，且不在当前检查路径中 if(Objects.nonNull(searchXidStamp) &amp;&amp; searchXidStamp &lt; this.stampMark)&#123; return false; &#125; // 标记事务戳 this.transactionStamp.put(searchXid, this.stampMark); Long waitingRecordUid = this.transactionWaitForRecord.get(searchXid); // 看当前事务有没有正在等待的Record记录 if(Objects.isNull(waitingRecordUid))&#123; return false; &#125; // 向上定位资源(相当于有向图的一条边指向后继节点) Long tarRecordControlledTransactionXid = recordControlledByTransaction.get(waitingRecordUid); if(Objects.isNull(tarRecordControlledTransactionXid))&#123; Log.logErrorMessage(ErrorMessage.VERSION_CONTROL_RESOURCE_ERROR); &#125; // 看获取目标记录的事务是否会造成死锁 return this.deepFirstSearchForDeadLock(tarRecordControlledTransactionXid); &#125; 有环的话就会回到某个节点，访问到戳 另外，有一个方法用以释放资源锁，当某个事务提交或者撤销后，就可以释放其持有的锁，并在图中注销 同时，还有一个方法用以选择某个方法来获取被释放的资源，按等待的顺序即FIFO来选择事务持有这个资源 VM对外提供接口 12345678910111213141516171819202122232425262728293031323334353637383940/** * @Author: 711lxsky * @Description: 事务开始 */ long begin(int transactionIsolationLevel) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 读取记录中的数据 */ byte[] read(long xid, long uid) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 插入记录数据 */ long insert(long xid, byte[] data) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 删除记录 * 实现的是将记录的XMAX设置为当前事务XID,这样后续事务就无法读取到这条记录 */ boolean delete(long xid, long uid) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 事务提交 */ void commit(long xid) throws WarningException, ErrorException; /** * @Author: 711lxsky * @Description: 事务撤销 */ void abort(long xid) throws WarningException, ErrorException; static VersionManagerImpl buildVersionManager(TransactionManager tm, DataManager dm) throws ErrorException &#123; return new VersionManagerImpl(tm, dm); &#125; 实现类 这个实现类同时实现了Record的缓存 成员变量 123456789101112private final TransactionManager tm; private final DataManager dm; /** * 档期那活跃的事务快照 */ private final Map&lt;Long, Transaction&gt; activeTransactions; private final VersionLockManager vlm; private final Lock selfLock; 逻辑操作 begin事务开始 创建一个新事务，然后将事务xid返回，同时在活跃事务表中进行注册 read读数据 先根据xid拿到事务，再调用缓存方法拿到Record，如果检测事务可见性通过就返回数据，最后释放缓存资源引用 insert插入数据 直接将需要插入的数据包装为Record的字节数组形式，并利用DM持久化 delete删除记录 拿到事务后检测事务可见性，再使用VersionLockManager进行资源获取尝试，再检测是否发生版本跳跃，再将目标记录的XMAX设置为当前事务xid commit提交事务 拿到事务后，将活跃快照表中的数据删掉，再调用VersionLockManager进行资源释放，再调用TM提交事务持久化 abort撤销事务 拿到事务后调用VersionLockManager进行资源释放，再调用TM撤销事务持久化 之所以撤销事务比较容易，是因为对于其他事务而言，只能看到处于已提交状态的事务所产生的数据，撤销后的事务不会对其他事务产生影响 IndexManager 索引管理 提供基于B+树的聚簇索引，索引数据直接插入数据库文件，而不需要经过版本管理 B+树节点 这里是有一个类BPlusTreeNode实现了B+树节点 结构 NodeHead: [LeafFlag][KeysCount][SiblingUID] LeafFlag byte类型，标识当前节点是否是叶子节点 KeyCount short类型，标识当前节点的关键字数量 SiblingUID long类型，标识当前节点的兄弟节点UID NodeBody: [SonNode0Uid][Key0][SonNode1Uid]…[SonNodeNUid][KeyN] SonNodeUid子节点Uid(唯一标识) Key 索引关键字 注意： 在叶子节点中uid和key一一对应，存储的就是底层数据 而在非叶子节点中，uid0是没有配对值的，因为默认其左侧是无限小，key0是和uid1配对的， 是uid1子节点中的最小数据，而keyN是MAX_VALUE无限大，以方便查找 每个Node都存储在一条DataItem中 这里和Mysql中的索引结构是有区别的，innodb引擎中的节点之间使用的是双向链表，可以比较方便的从后往前进行范围查询 成员变量 12345678910111213141516171819/** * 存放一个B+树的引用，方便使用dm */ private BPlusTree bPlusTree; /** * 方便管理数据 */ private DataItem dataItem; /** * 节点数据 */ private SubArray nodeData; /** * 当前节点的唯一标识uid */ long nodeUid; 实现逻辑 配置类中设置有一个平衡因子，当节点的子节点数量达到平衡因子的两倍时，进行分裂 所以新建一个节点时，会直接申请完整的所需空间NODE_SIZE = NODE_HEAD_SIZE + NODE_SON_COUPLE_SIZE * (NODE_BALANCE_NUMBER + 1) * 2; 新建节点 提供新建根节点和叶子节点的字节数组形式方法 根节点放入左右子节点的uid，同时设置叶子标志为false，以及节点数量为2 叶子节点设置叶子标志为true，节点数量为0 查找 精确查找 参数是一个Key，表示目标值，这是实现的是遍历查找（也能改成二分） 如果在这一层找到了，就返回下一层的uid值，非叶子节点就返回下一层节点；叶子节点就是返回实际存储数据位置的持久层位置 如果没有找到，就返回兄弟节点uid，让调用方可以切到右边去找 范围查找 参数是两个边界值，直接下到节点中去，先定位到大于等于leftKey的位置，然后往右走拿到后续符合条件的uid 如果这个节点还没走完就超出了右边界就返回 反之就同时返回兄弟节点uid 插入 参数是插入的uid和key 先找到第一个 &gt;= key 的位置，如果没找到而且当前节点有兄弟节点就切到兄弟节点去插 如果没有找到且没有兄弟节点，或者是找到了，就在当前节点中插入 如果插入的节点是叶子节点，直接将uid和key插入即可 如果插入的是非叶子节点，因为其uid和key不是对应关系，所以是将kth位置的key和kth + 1位置uid数据覆盖 插入之后，会立即判断是否需要分裂，如果节点数达到2 * 平衡因子就进行分裂 分裂 逻辑也比较好理解： 创建新节点 复制当前节点的叶子/非叶子属性、兄弟节点信息给新节点 将新节点的子节点数量设置为平衡因子 将右侧的半边数据分给新节点 将新节点持久化 更新当前节点的兄弟节点为新节点 B+树 有一个B+树类，索引的数据直接被插入到数据库文件进行持久化，不经过版本管理 成员变量 1234567891011121314/** * @Description: 数据管理 */private DataManager dm;/** * @Description: 用以对 rootUid 数据进行处理 */private DataItem rootUidDataItem;/** * @Description: 自身资源锁 */private Lock selfLock; 实现逻辑 构建和加载B+树 初始构建时，创建一个叶子节点作为初始根节点，然后利用DM持久化，并拿到这个节点的标识uid 加载B+树时，则利用DM从持久层拿到数据，然后包裹成B+树对象 更新节点 这个方法用以更新一个节点为真正的根节点，构建一个字节数组形式的根节点之后持久化，并设置为根节点（也可以理解为非叶子节点） 数据查找 提供一个方法用以搜索下一层能够满足条件的节点 借助B+树节点类型实现，直接查找满足特定条件的节点 提供一个方法查找查找符合条件的叶子节点 提供方法在叶子节点中进行范围查找 也是借助B+树节点类实现 插入数据 暴露给外部模块以进行数据的插入 如果插入位置是叶子节点，下到内部插入方法，借助B+树节点进行插入，然后直接返回结果 如果插入位置是非叶子节点，就还需要借助精确查找定位到下一层去，进行递归插入，如果插入完成了且发生分裂，还需要更新分裂节点的插入 上面完成后返回插入结果，如果发生分裂，就需要更新根节点 注意：可能需要进行多次节点分裂更新，所以这里比较绕 StatementParser 语句解析模块 这个模块用以进行SQL语句的解析 逻辑实现 Tokenizer 分词器 这个类用以将文本分割为一些最小单位的token 成员变量 12345678910111213141516171819/** * 语句 */ private final byte[] statement; /** * 当前在语句中的分析定位 */ private int curAnalysisPos; /** * 当前解析出的token */ private String curToken; /** * 是否需要刷新token,即将下一个token解析出来 */ private boolean needFlushToken; 实现方法 Tokenizer(byte[] statement)： 构造函数，接收一个字节数组作为需要分割的语句，并初始化相关成员变量 String peek() throws WarningException： 获取当前解析出的token，如果需要刷新token，则先解析下一个token void pop()： 强制要求刷新token，即将下一个token解析出来 String nextMetaState() throws WarningException： 解析下一个token，具体实现根据不同的字符类型进行处理 String nextQuoteState() throws WarningException： 处理引号包含的toke String nextTokenState()： 处理只含字母、数字、下划线的token Byte peekByte()： 获取当前分析位置的字符 void popByte()： 将当前分析位置向后移动一位 String StateAnalysisWrong() throws WarningException： 处理解析错误的情况 byte[] getStatement()： 获取完整的解析语句 此类的分词方法结合字符串配置类实现 StatementParser 语句解析器 借助分词器，逐步解析语句，并返回相应的解析结果类，用以供上层模块使用，其中还包含解析where语句，但是比较简陋 这里的判断是写死的，所以如果改动的话会比较麻烦，正规的做法应该是使用语法树 1234567891011121314151617181920212223242526272829303132# begin事务开始语句，设置事务隔离级别begin [isolation level] [read committed | repeatable read]# commit事务提交语句commit# abort事务回滚语句abort# create table 建表语句，指定字段和索引create table [tableName] [fieldName1][fieldType1], ... [fieldNameN][fieldTypeN] (index [indexName1]...[indexNameM])# drop table 删除表语句drop table [tableName]# select 查询语句, where语句是可选的select * | [fieldName1], [fieldName2], ... from [tableName] where ...# insert 插入语句insert into [tableName] values [value1], [value2], ...# delete 删除语句delete from [tableName] where ...# update 更新语句update [tableName] set [fieldName] = [value] where ... TableManager 表管理模块 这个模块实现的是表、字段管理，当上层模块调用语法解析器解析出结果后面，就会调用这个模块进行表的创建、数据修改 表结构实现的是在用一个数据库/架构下的表使用链表的形式进行串联 提供接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @Author: 711lxsky * @Description: 开启事务 */TBMSetting.BeginResult begin(SPSetting.Begin begin) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 提交事务 */byte[] commit(long xid) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 撤销事务 */byte[] abort(long xid) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 创建表 */byte[] create(long xid, SPSetting.Create create) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 插入数据 */byte[] insert(long xid, SPSetting.Insert insert) throws WarningException, ErrorException;byte[] drop(long xid, SPSetting.Drop drop) throws WarningException;/** * @Author: 711lxsky * @Description: 查询数据 */byte[] select(long xid, SPSetting.Select select) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 删除数据 */byte[] delete(long xid, SPSetting.Delete delete) throws WarningException, ErrorException;/** * @Author: 711lxsky * @Description: 更新数据 */byte[] update(long xid, SPSetting.Update update) throws WarningException, ErrorException; 逻辑实现 Field 表字段实体类 此类是表字段的模型，记录有字段的uid唯一标识，字段类型，索引uid，同时成员变量中有一个字段索引关联的B+树 持久化时会调用DM写入数据，同时提供取出数据转化为本类的方法 Table实体类 这个类是表的模型，存储有当前表的uid，下一个表的uid，以及该表字段列表，同样持久化时也是调用DM写入，实现字节数据解析为当前类方法 TBM实现的表数据管理部分就是基于这个实体类在做，调用这个类的Insert、Update、Select方法 Booter启动类 这个类时表管理器的启动类，存储有第一张表（头表）的信息，更新此文件时会先创建一个临时文件再替换为实际文件 TableManager 实现 提供创建方法和打开方法，分别用以创建启动类和打开启动类文件拿到表信息 实现类中包含表缓存信息，以及针对某个事务的一系列表缓存，一开始就会将表信息放入缓存中 创建表也会放入缓存，修改表会进行相应持久化，删除表则会将缓存中数据删除，持久层不用删 传输模块 这个模块用以在创建的Socket基础上进行数据传输 自定义数据包 这里自定义了一个数据包实现类，成员变量是一个字节数组和一个异常 123456789101112131415161718// 原始数据 byte[] data; // 异常信息 Exception exception; public DataPackage(byte[] data, Exception exception) &#123; this.data = data; this.exception = exception; &#125; public byte[] getData() &#123; return data; &#125; public Exception getException() &#123; return exception; &#125; 编解码器 通信数据使用的是二进制，这个编解码器负责将自定义数据包和字节数组之间的相互转换 1234567891011121314151617181920212223242526272829303132333435/** * @Author: 711lxsky * @Description: 数据编码，将数据包转换成字节数组 */ public static byte[] dataEncode(DataPackage dataPackage)&#123; Exception dataException = dataPackage.getException(); if(Objects.nonNull(dataException))&#123; return Bytes.concat(new byte[]&#123;TransportSetting.DATA_IS_EXCEPTION_TRUE&#125;, dataException.getMessage().getBytes()); &#125; else &#123; return Bytes.concat(new byte[]&#123;TransportSetting.DATA_IS_EXCEPTION_FALSE&#125;, dataPackage.getData()); &#125; &#125; /** * @Author: 711lxsky * @Description: 数据解码，将字节数组转换成数据包 */ public static DataPackage dataDecode(byte[] data) throws WarningException &#123; if(data.length &lt; TransportSetting.DATA_MIN_LENGTH_DEFAULT)&#123; Log.logWarningMessage(WarningMessage.DATA_ERROR); &#125; // 正常数据 if(data[0] == TransportSetting.DATA_IS_EXCEPTION_FALSE)&#123; return new DataPackage(Arrays.copyOfRange(data, TransportSetting.DATA_EXCEPTION_MARK_OFFSET, data.length), null); &#125; // 异常信息 else if(data[0] == TransportSetting.DATA_IS_EXCEPTION_TRUE)&#123; return new DataPackage(null, new RuntimeException(new String(Arrays.copyOfRange(data, TransportSetting.DATA_EXCEPTION_MARK_OFFSET, data.length)))); &#125; else &#123; Log.logWarningMessage(WarningMessage.DATA_ERROR); return null; &#125; &#125; 编码时，会根据是有异常，如果有异常就将异常信息放到字节数组中发出，并设置一个校验位；解码时，根据校验位来判断是将二进制数据转换为data还是异常 Transporter 传输器 传输器实现类基于socket，先构建获取自socket读流、写流 同时提供方法实现十六进制数据和字节数组之间的互相转换 写时，将字节数据转换为十六进制数据 读时，将十六进制数据转换为字节数据 向外提供 Packager 数据包装传输器 暴露一个Packager类，以传输器为成员变量，提供发送数据、接受数据方法 服务端 Server类 Server类中以TBM和一个int类型的端口为成员变量，只有一个启动方法，先尝试创建一个监听特定端口的ServerSocket，然后构建一个线程池，之后进入一个true条件的while循环，不断接收客户端的连接请求，对每个连接进行处理，然后创建一个SocketHandler处理器，传入tbm和socket连接，并交给之前构建的线程池去执行 SocketHandler 处理器 这个类继承了Runnable，算是一个线程类，先打印和客户端的连接信息，然后创建一个传输模块提供的Packager，然后创建一个Executor执行器，利用packager接收客户端数据，再交给执行器执行SQL语句，得到结果后封装返回 Executor 服务端SQL语句解析执行器 这个类以xid和tbm为成员变量，调用SP模块静态方法解析SQL语句，然后根据返回的类型调用tbm做实际的数据操作 Launcher 服务端启动类 这个类用以进行服务端的启动，借助 org.apache.commons.cli创建命令行交互，指导创建或者打开数据库，去调用TM、DM、VM、TBM模块方法，如果是打开数据库就会启动Server，准备监听客户端 客户端 Client类 以Packager为成员变量，实现有一个execute方法以进行数据的收发 Shell 命令行类 以Client为成员变量，比较简陋地读取用户输入，然后调用Client以发送、拿到返回的数据，同时执行Client的close方法，关闭数据包 Launcher 客户端启动类 同样，客户端也有一个启动类，先创建一个ClientSocket，然后构建Packager，最后构建Shell，然后启动Shell 结语 整体来说项目难度还是不低的，比起业务上的设计我感觉更考验Java基础，而且项目整体设计和把握也需要一定的架构能力 哎哎，还是得继续撸码🤥","categories":[{"name":"Project","slug":"Project","permalink":"http://711lxsky.github.io/categories/Project/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Linux(2)","slug":"blog20","date":"2024-05-07T22:00:00.000Z","updated":"2024-05-08T11:00:00.000Z","comments":true,"path":"2024/05/07/blog20/","link":"","permalink":"http://711lxsky.github.io/2024/05/07/blog20/","excerpt":"","text":"记录一次Manjaro系统的惊险修复 背景 这次真不是水 前几天五一假期中期之时， 因为跑一个React项目的缘故， 偶然间修改了根目录下/usr路径的权限。😇类似于: 1sudo chmod -R 777 /usr 后续执行sudo xxx指令就报错/usr/bin/sudo 必须属于用户 ID 0(的用户)并且设置 setuid 位🤕 哎哎，自然是权限问题，因为Linux系统下的sudo权限必须交给root用户 (题外话说一下setuid, setuid位是一种特殊权限位，当设置在某个可执行文件上时，允许任何用户在执行该文件时拥有文件所有者的权限。对于sudo这样的命令，这是必要的，因为它允许非root用户临时提升权限执行管理任务) 现在sudo`也用不了，不能把权限给赋回去，好吧，开始救命 解决步骤 疯狂搜索 用这个报错信息一查，结果发现不止我一个傻春😝 靠前的搜索结果说的是重启进安全/紧急/单人模式，然后手动把权限改回去；或者直接当前状态下切到root用户，but这个方案似乎并没有起作用，su之后输密码重复试了很多次都还是不行，猜测也是/usr的改动导致的 问问拷打😎 抱着死马当作活马医的想法，就跑过去问GPT，特别提一下，是模型gpt-4-0125-preview，(另外，感谢@LHX的维护, 让我能够长期免费使用到GPT)给出的解决方案和搜索结果类似 : 当时电脑上浏览器开了不少窗口，同时又打算重启电脑，故用手机在问:) 正式开始 1. 进入单人模式 重启之后先进到Majaro启动的编辑界面(我这里是按E即进)， 然后定位到Linux开头那一行，加上single init=/bin/bash同时将ro改成rw， 以读写模式挂载 2. 指令修复 这里先把几个系统分区挂上 12lsblk # 查看分区mount /dev/sda&#123;x&#125; /mnt # 挂载 然后直接去修改权限 12chown root:root /usr/bin/sudochmod 4755 /usr/bin/sudo 先修改文件目录所有者， 再该权限 解释4755: 第一位（4）表示特殊权限中的SetUID位（SUID）。当应用于可执行文件时，SUID允许任何用户在执行该文件时，暂时拥有文件所有者的权限。这对于需要普通用户以root或其他特权用户权限执行某些操作的情况非常有用，例如/usr/bin/passwd命令允许用户更改密码，就是利用了SUID权限。 接下来的三位（7）表示文件所有者的权限，拥有读（r=4）、写（w=2）、执行（x=1）权限，合起来就是7（4+2+1），即rwx。 再接下来的三位（5）表示与文件所有者同组的用户的权限，拥有读（r=4）和执行（x=1）权限，没有写权限，即rx。 最后的三位（5）表示其他用户的权限，同样拥有读和执行权限，没有写权限。 总结来说，权限4755赋予了文件所有者全部权限，文件所属组用户和其他用户有读取和执行权限，并且由于设置了SUID位，任何用户执行该文件时都将暂时拥有文件所有者的权限。这种权限设置常见于需要提升权限执行的二进制程序上 3. 重启测试 重启之后sudo确实是好了，但是又出现了新问题😓 首先是zsh打开的时候就报错，大致意思是配置文件无法找到，补全失效 然后又有AppImage报错You might still be able to extract the contents of this AppImage if you run it with the --appimage-extract option. See https://github.com/AppImage/AppImageKit/wiki/FUSE for more information 同时网络驱动貌似也死了 4. 修复新问题 所以我就去先修AppImage，这个地方我尝试着把所有分区重新挂载一遍貌似好了 网络问题，就只能USB连线使用手机共享网络 然后修zsh，卸载之后重装，还是不行，我以为是环境变量设置未生效，就打算重启看看 好么，重启结果卡住了，😡卡在启动界面进不去了卧槽，就靠着Ctrl+Alt+F3切换到tty模式，刚进去就看到提示No space left on device，用df -h查看磁盘占用情况，就发现/var分区20G全部占满，再使用sudo du -ahx /var | sort -rh | head -20查看目录下占用内存最大的文件，就看到有个/var/log/cups/error_log文件，大概有10多G,查阅之后知道这个日志是通用Unix打印系统(Common Unix Printing System)产生的，应该没啥用，就直接删除，但是因为命令提示行之前设置的是能够打印中文，所以很多提示都是方形的空白字符，根本看不清，删了几次才成功 不少次尝试后成功进入系统，我想要试试zsh配置重新设置之后能否生效，使用source ~/.zshrc，结果报错 12345678910警告：目录权限不一致 /usr/bin/ 文件系统：777 软件包：755 警告：目录权限不一致 /usr/lib/ 文件系统：777 软件包：755 警告：目录权限不一致 /usr/lib/zsh/ 文件系统：777 软件包：755 警告：目录权限不一致 /usr/lib/zsh/5.9/ 文件系统：777 软件包：755 警告：目录权限不一致 /usr/lib/zsh/5.9/zsh/ ... 突然想到/usr之前被我修改权限了，但是只改回了/usr/bin/sudo，所以就打算手动把其他目录改回来，结果一个不小心，又把/usr/bin目录改了我是SB🤡，导致又要进单人模式，所幸有了之前的经验，这次改的很快，重启之后去查有没有比较方便修复文件系统权限的命令，果然有： 12yay -S pacman-fix-permissionssudo pacman-fix-permissions 先装好pacman-fix-permissions，然后去执行命令修复权限 我看命令执行情况，貌似是分析本机应用依赖包，然后全局扫描，测试权限，再改回来，大概跑了半个小时，重启之后系统修复，完好如初！😀 回顾总结 还好自己没有直接想着重装，而是尝试去修复(毕竟也不想再重装配环境了) 下次别在手贱不过脑子直接改权限了！🥲 其实之前用Linux的时候，也出过不少问题， 先是在一台主机上装了Ubuntu，第一次问题是不小心使用sudo rm -f /etc(当时是删别的某个路径，结果新开一个命令行忘切目录)把核心配置全删了，啥指令都不起作用，当时打算从别人那儿把/etv拷过来，结果挂载不上去，U盘调不出来，重装！ 再有，是这个重装的Ubuntu系统，因为默认装的Gnome图形界面，非常不稳定，经常应用卡退，换成KDE，就直接红屏了；没办法，先改回去Gnome，然后看有人说输入法可能会造成应用闪退，卸掉，没起作用；修显卡驱动，重启，卡死了，文件系统崩溃，网络驱动也寄了，全挂了，直接重装Kubuntu了(这个系统用的倒是还好，没啥问题) 笔记本上的Manjaro，之前有一次分区不合理，想要合并分区来着，结果出了无法修复的问题，也重装过一次。有一说一，Manjaro是我用的最舒服的，日常没啥问题 哎哎，下次出问题继续修，反正是折腾😆","categories":[{"name":"Linux","slug":"Linux","permalink":"http://711lxsky.github.io/categories/Linux/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"借助SpringBoot实现异步调用","slug":"blog19","date":"2024-03-31T21:00:00.000Z","updated":"2024-03-31T21:00:00.000Z","comments":true,"path":"2024/03/31/blog19/","link":"","permalink":"http://711lxsky.github.io/2024/03/31/blog19/","excerpt":"","text":"基于SpingBoot实现异步调用 小水一下 😋哈，终于抓住3月的尾巴，更篇文章～～ 来学校之后，把Mysql八股基本过了一遍，微服务又去熟悉了一下，还得边学计组计网操作系统(天杀得jwc反正迟早得学)。每天leetcode倒是坚持了下来，就是平常得应付学校不少破事儿，感觉精力越来越不及以前充沛了😢 最近在准备轮子项目，一个简易数据库(偷师某位来自HIT的学长)，支持读提交、可重复读事务隔离级别，包含页面索引，支持MVCC、2PL等等，目前差不多完成一半了，之后完成并且测试通过(这个flag还是不立了)之后，肯定会好好写篇文章把注释搬出来总结一下(哈准备接受拷打)原意是打算做6.824(现6.5840)，把分布式实践一下，但是不确定有没有连贯的精力，还得准备个微服务项目和八股，所以还是选择了写这个 好了好了，回归正题 对于异步调用，最开始听到是看JUC八股的时候；再后来在微服务中，某个模块向消息队列发送处理消息，处理模块接收消息处理，也是异步调用的思想。 上游的“我”这里只需要处理好我需要做的任务，剩下的交给下游“你”去完成，“我”只需要返回&quot;我&quot;的任务执行情况。这里的上下游可能是单机中的不同进程，也可以是不同服务器上的不同服务😎 正巧，hx从老师那里接了个需求很模糊的项目，需要调用后台服务执行一个Python脚本，这个脚本运行时间可能是几分钟～十多分钟。自然不能一直让前台等待执行结果，做一个Websocket感觉又比较大材小用，于是我就弄了个异步调用，将接收请求进程和运行脚本线程分开，前台只需要轮询查询执行情况即可。原本我还以为写起来比较麻烦，没想到写架子就花了不到一个小时，反而是层级解耦花了不少时间(掌嘴😤) 具体实现 这里本就是借助SpringBoot实现，所以方便的很 依赖 先得有依赖(这里使用Maven，所以在pom.xml中加入)： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;你的Spring Boot版本对应的版本号&lt;/version&gt;&lt;/dependency&gt; 但是这个依赖是SpringBoot的核心依赖之一，一般只要有starter就行了: 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 线程池配置 一般还需要配置一下异步调用线程池，针对服务挂载端的配置调整线程池、任务队列 贴一下我的写法(写在配置文件中，方便一键更改)： application.properties中： 123456789# ------异步线程池配置-------# 线程池核心线程数async-settings.corePoolSize=2# 线程池最大线程数async-settings.maxPoolSize=4# 任务队列最大容量async-settings.queueCapacity=100# 线程池线程名前缀async-settings.thread-name-prefix=Async- 写个配置类(用了lombok): 1234567891011121314151617181920212223242526@Setter@Getter@ConfigurationProperties(prefix = &quot;async-settings&quot;)@Configuration@EnableAsyncpublic class AsyncConfig extends AsyncConfigurerSupport &#123; private int corePoolSize; private int maxPoolSize; private int queueCapacity; private String threadNamePrefix; @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(corePoolSize); executor.setMaxPoolSize(maxPoolSize); executor.setQueueCapacity(queueCapacity); executor.setThreadNamePrefix(threadNamePrefix); executor.initialize(); return executor; &#125;&#125; 注意注解EnableAsync表示启用异步调用 然后在需要异步调用执行的方法上加上@Async注解即可 一般我会把方法实现为返回值为CompletableFuture包裹泛型(CompletableFuture&lt;T&gt; implements Future&lt;T&gt;, CompletionStage&lt;T&gt;)，异步方法中发生的异常默认是不会被调用者捕获的。如果你的异步方法返回Future，那么异常将会被封装在Future中，你可以通过Future.get()方法来获取，另外获取执行结果也比较方便 结语 哎哎，真方便真快啊 不过最近看到有个Java框架新秀Solon; Github地址 Gitee 现在已经是Gitee的GVP项目了，看作者在官方群里说效率挺高，和Gin相差无几。之前看了下貌似确实挺轻的，之后好好看看 周末结束力，明天又是早八点半😇","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://711lxsky.github.io/categories/SpringBoot/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"二叉树的前中后序遍历Morris实现","slug":"blog18","date":"2024-02-10T18:00:00.000Z","updated":"2024-02-10T18:00:00.000Z","comments":true,"path":"2024/02/10/blog18/","link":"","permalink":"http://711lxsky.github.io/2024/02/10/blog18/","excerpt":"","text":"二叉树的Morris前中后序遍历 水水 新年好捏🎆 24年的大年初一，终于更一下年前就打算弄的一个文章。 在力扣做hot100的时候，做到树的章节，开头就是二叉树的中序遍历实现，嘿，递归和正常非递归实现都好说，但是有个Morris方法，把空间复杂度降到O(1)，刚好很久之前做这题的时候也是一知半解，仔细一看和线索二叉树有关，所以打算好好看看 先说说递归和一般非递归(迭代)遍历实现 这俩本质上不差多少，都是用栈实现，只是一个是系统栈，一个是自定义的栈 先把树节点结构定义一下，基于Go书写，且定位为LeetCode原题: 二叉树前序遍历 二叉树中序遍历 二叉树后序遍历 12345678type TreeNode struct &#123; // 存储值 Val int // 左子节点 Left *TreeNode // 右子节点 Right *TreeNode &#125; 递归实现 时间复杂度是O(n)，空间复杂度是O(n)，使用系统栈 很好理解嘛，到达当前节点后，直接去到左右子节点，一直到叶子节点，再逐层调用返回 前序遍历 12345678910111213func preorderTraversal(root *TreeNode) (vals []int) &#123; var preorder func(*TreeNode) preorder = func(node *TreeNode) &#123; if node == nil &#123; return &#125; vals = append(vals, node.Val) preorder(node.Left) preorder(node.Right) &#125; preorder(root) return&#125; 中序遍历 12345678910111213func inorderTraversal(root *TreeNode) (res []int) &#123; var inorder func(node *TreeNode) inorder = func(node *TreeNode) &#123; if node == nil &#123; return &#125; inorder(node.Left) res = append(res, node.Val) inorder(node.Right) &#125; inorder(root) return&#125; 后序遍历 12345678910111213func postorderTraversal(root *TreeNode) (res []int) &#123; var postorder func(*TreeNode) postorder = func(node *TreeNode) &#123; if node == nil &#123; return &#125; postorder(node.Left) postorder(node.Right) res = append(res, node.Val) &#125; postorder(root) return&#125; 非递归(迭代)实现 时间复杂度是O(n)，空间复杂度是O(n)，使用自定义栈 和递归一样，只是自己手动去控制栈，直接深入到叶子节点，然后再自底向上去走节点，逐层遍历完 前序遍历 1234567891011121314func preorderTraversal(root *TreeNode) (vals []int) &#123; stack := []*TreeNode&#123;&#125; node := root for node != nil || len(stack) &gt; 0 &#123; for node != nil &#123; vals = append(vals, node.Val) stack = append(stack, node) node = node.Left &#125; node = stack[len(stack)-1].Right stack = stack[:len(stack)-1] &#125; return&#125; 中序遍历 1234567891011121314func inorderTraversal(root *TreeNode) (res []int) &#123; stack := []*TreeNode&#123;&#125; for root != nil || len(stack) &gt; 0 &#123; for root != nil &#123; stack = append(stack, root) root = root.Left &#125; root = stack[len(stack)-1] stack = stack[:len(stack)-1] res = append(res, root.Val) root = root.Right &#125; return&#125; 后序遍历 123456789101112131415161718192021func postorderTraversal(root *TreeNode) (res []int) &#123; stk := []*TreeNode&#123;&#125; var prev *TreeNode for root != nil || len(stk) &gt; 0 &#123; for root != nil &#123; stk = append(stk, root) root = root.Left &#125; root = stk[len(stk)-1] stk = stk[:len(stk)-1] if root.Right == nil || root.Right == prev &#123; res = append(res, root.Val) prev = root root = nil &#125; else &#123; stk = append(stk, root) root = root.Right &#125; &#125; return&#125; Morris遍历 好了，重头戏来了 其实这种方式是利用叶子节点的空指针，将某个父节点的中序遍历前驱节点的右指针指向父节点，使得遍历完左子树后得以返回当前父节点 即：对于一个节点，如果其具有左子树，那么将其左子树上的最右节点作为其前驱节点，第一次访问时先将其右指针指向此节点，作为第二次访问判断左子树遍历完成的标志。 这样，就可以使得让有左孩子的节点被访问两次，没有左孩子的节点被访问一次 在此基础上实现前中后序遍历： 前序 Morris遍历加工成先序遍历的规则是： 如果一个节点只能被访问一次，被访问时加入答案列表 如果一个节点能被访问两次，在第一次被访问时加入列表 代码实现 1234567891011121314151617181920212223func preorderTraversal(root *TreeNode) (res []int) &#123; for root != nil &#123; if root.Left != nil &#123; processor := root.Left for processor.Right != nil &amp;&amp; processor.Right != root &#123; processor = processor.Right &#125; // 左子树安全 if processor.Right == nil &#123; res = append(res, root.Val) processor.Right = root root = root.Left &#125; else &#123; // 左子树已经遍历完全 processor.Right = nil root = root.Right &#125; &#125; else &#123; // 没有左子树 res = append(res, root.Val) root = root.Right &#125; &#125; return&#125; 中序 Morris遍历加工成中序遍历的规则是： 如果一个节点只能被访问一次，被访问时加入答案列表 如果一个节点能被访问两次，在第二次被访问时加入列表 代码实现 123456789101112131415161718192021222324func inorderTraversal(root *TreeNode) (res []int) &#123; // 使用morris遍历 for root != nil &#123; // 先看有无左子节点，需要寻找的是当前节点的中序遍历前驱节点 if root.Left != nil &#123; processor := root.Left for processor.Right != nil &amp;&amp; processor.Right != root &#123; processor = processor.Right &#125; if processor.Right == nil &#123; processor.Right = root root = root.Left &#125; else &#123; // 已经遍历完了左子树 res = append(res, root.Val) processor.Right = nil root = root.Right &#125; &#125; else &#123; // 没有左子树，直接往右走 res = append(res, root.Val) root = root.Right &#125; &#125; return&#125; 后序 Morris遍历加工成中序遍历的规则是： 如果一个节点能被访问两次，在第二次被访问时自底向上加入该节点左子树的右边界进答案列表 当所有节点遍历完后，单独自底向上加入整棵树的右边界 代码实现 12345678910111213141516171819202122232425262728293031323334353637func postorderTraversal(root *TreeNode) (res []int) &#123; // 这个比较麻烦，需要实现倒序、收割右子树 reveseInts := func(nums []int) &#123; n := len(nums) for i := 0; i &lt; n/2; i++ &#123; nums[i], nums[n-i-1] = nums[n-i-1], nums[i] &#125; &#125; addPath := func(node *TreeNode) &#123; size := len(res) for node != nil &#123; res = append(res, node.Val) node = node.Right &#125; reveseInts(res[size:]) &#125; for root != nil &#123; if root.Left != nil &#123; // 左子树存在 processor := root.Left for processor.Right != nil &amp;&amp; processor.Right != root &#123; processor = processor.Right &#125; if processor.Right == nil &#123; processor.Right = root root = root.Left &#125; else &#123; processor.Right = nil addPath(root.Left) root = root.Right &#125; &#125; else &#123; root = root.Right &#125; &#125; addPath(root) return&#125; 结语唠唠 Morris遍历的话，确实可以降低空间复杂度，但是它遍历时改变了二叉树的结构，如果在多线程的场景下，多个线程同时读写(一个写，多个读)某个二叉树的数据，那会非常危险。如果明确要求不可修改二叉树，那这种方案就不适用 有空看能不能补补图(太懒力:| 溜了~~","categories":[{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://711lxsky.github.io/categories/Arithmetic/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://711lxsky.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Java-语法(1)","slug":"blog17","date":"2023-12-23T01:48:00.000Z","updated":"2023-12-23T01:48:00.000Z","comments":true,"path":"2023/12/23/blog17/","link":"","permalink":"http://711lxsky.github.io/2023/12/23/blog17/","excerpt":"","text":"Java笔记语法篇 基本数据类型 类型 位数 字节数 默认初始值 取值范围 byte 8 1 0 -128(27)~127 short 16 2 0 -32768(215)~32767 int 32 4 0 -2147483648(231)~2147483647 long 64 8 0L -9223372036854775808(263)~9223372036854775807 char 16 2 ‘u0000’ 0~65535(216-1) float 32 4 0f 1.4E-45~3.4028235E38 double 64 8 0d 4.9E-324~1.7976931348623157E308 boolean false ture / false 对于boolean 在Java虚拟机中对其支持有限: 单个boolean类型的变量表达式在编译时会被转换成int类型，用1表示true，用0表示false，即4个字节; 而对boolean数组的操作则同byte数组等价，即1个字节。另外，其具体实现也依赖于JVM厂商 上述基础类型对应的包装类型 Byte、Short、Integer、Long、Character、Float、Double、Boolean ； 将基本类型转换成包装类型即“装箱(boxing)”，反之“拆箱(unboxing)” 基本类型与包装类型的区别 基础类型不具备对象特性，所以: 在需要使用Object的地方(比如泛型)必须是包装类型 且作为类,包装类型可以为null；==对于基本类型是比较值，对于包装类型则是比较内存地址，包装类型对象之间值的比较用equals()方法 基本数据类型的局部变量放在Java虚拟机的局部变量表/栈中，未被static修饰的成员变量放在堆内存中；而对于包装类，实例放在堆，引用放在栈。一般基本类型更高效。 基础类型相比包装类型占用空间小 自动拆装箱与包装类缓存机制 12Integer num1 = 711;int num2 = num1; 说明 这里前一条语句发生自动装箱，将int转换为Interger，实际上使用的是包装类的ValueOf()方法 --&gt; Integer.ValueOf()；后一条语句发生自动拆箱，调用intValue()方法 --&gt; num1.intValue() 自动拆装箱发生 将基本数据类型放入集合类（装） 基本类型与包装类型大小比较（拆） 包装类型的运算（拆） 三目运算符中，第二、三位操作数有包装类时就拆 方法参数/返回值类型不匹配，自动拆装 包装类缓存机制 大部分包装类（除了Float、Double）使用缓存机制来提升性能： 在一定范围内利用自动装箱（ValueOf()方法）创建包装类对象时，会从缓存（常量池）中寻找指定数值（一般来说各个包装类默认创建了一个静态数组cache[],对应范围，所以只要在这个范围内理论上都有），未找到则新建对象并返回引用；找到则直接返回引用 这个范围： Byte、Shotr、Integer、Long：-128 ~ 127 Character: 0 ~ 127 Boolean: True、False 不在这个范围自动装箱或者直接new的包装类都会新建一个对象，且不会放入缓存，也不会复用（存储于堆空间） 由于包装类缓存机制，从缓存得来的对象引用比较时==(比地址)会为true，新建而来则为false，所以包装类对象实例之间值的比较最好用equals()方法（包装类默认重写了equals()方法，先看类型，再比较值） 另外，频繁拆装箱会影响系统性能，尽量避免不必要的拆装箱操作 高精度计算 虽说float和double可以满足大部分开发需要，但是精度在某些场景下仍然不够，这时候就需要BigDecimal来进行浮点数的创建运算： 构造 为防止精度丢失，推荐使用BigDecimal(Sting val)构造方法或者BigDecimal.valueOf(double val)静态方法（此方法内部使用Double的toString()方法，采用双精度浮点数(double)截断策略）来创建对象（实际上BigDecimal支持使用int、double、long、String来作为构造方法的参数，但是使用double的构造方法结果有一定的不可预知性） 运算 运算方法： 加 --&gt; add() 减 --&gt; subtract() 乘 --&gt; multiply() 除 --&gt; divide()，且最好尽量使用3参数版本(num除数,scale保留小数位数,roundingMode保留规则)，以针对出现无限循环小数的情况 大小比较 --&gt; compareTo()（忽略精度scale） ，-1即小于，0是等于，1为大于 注意点 最好不使用equals()方法比较值（会比较精度，1.0和1就会不相等） setScale()方法设置保留小数位、保留规则(建议为RoundingMode.HALF_EVEN，四舍六入五成双) 格式化可结合NumberFormat类使用 长整数计算 既然有高精度浮点运算，那么在整数区域也有长整数BigInteger类型，来处理Integer、Long位数不够的情况： 构造 构造方法：BigInteger类支持的构造方法有不少，可以传入byte []、char []、String、int、int []、long，同时还可以加入更多参数指定进制规则等等 运算 同理，因为位数过高，所以肯定没法用常规的运算符进行运算，只能使用其类方法： add() --&gt; 加 subtract() --&gt; 减 multiply() --&gt; 乘 divide() --&gt; 除 mod() --&gt; 取模(参数需要&gt;=0) remainder() --&gt; 求余 pow() --&gt; 平方(同理，参数需&gt;=0) abs() --&gt; 绝对值 negate() --&gt; 相反值 compareTo() --&gt; 比较大小，规则同BigDecimal 另外 还可以使用xxxValue()方法，将BigInteger转换成基本数据类型，亦或者使用toString()方法或者toByteArray()方法转换成某种进制的字符串/字节数组 求余和取模 这二者是有区别的（不光是Java，其他高级语言也是）: 对于整数基本类型，%就是求余，而Math.floorMod()方法才是取模。 当参与运算的两个数符号不一致时，对于a模b，运算结果符号与b一致；而a余b结果符号则和a相同。因为对于r=a - c*b，取模时c会向负无穷方向舍入（floor()方法），而求余则向0方向舍入（fix()方法） 移位运算符 &lt;&lt; 左移运算符，高位丢弃，低位取零。x &lt;&lt; 1在不溢出的情况下相当于x * 2 &gt;&gt; 右移运算符，高位补符号位(即正数高位补0，负数高位补1)，低位丢弃。所以 x &gt;&gt; 2 相当于 x / 2 &gt;&gt;&gt; 无符号右移，和&gt;&gt;不同的是所有空位都以0补齐 注： 移位操作实际上支持的类型只有int和long，编译器对short、byte、char类型位移前都会先转换为int再操作 移位位数超过数值所占位数时会先求余%再移，int对应32位，long对应64位 方法重写 重写是子类对父类方法的重新改造，外部样子(原本的框架)不变，改变内部逻辑 重写规范： 构造方法无法重写 父子方法名、参数列表必须相同 子类方法访问修饰符范围大于等于父类 子类方法返回值类型应和父类方法相等或者更小 子类方法抛出的异常范围小于等于父类 如果父类方法访问修饰符为private/final/static，那么子类就无法重写此方法 方法的可变长参数机制 Java5提供了可变长参数，允许在调用方法时传入不定长度的参数： 语法 在参数类型后跟一个...即可： 12345 public void changeArgs(int ... args)&#123; for(int arg : args)&#123; System.out.println(arg); &#125;&#125; 注意 一个方法有且仅能有一个可变长参数 可变长参数只能作为此方法的最后一个参数 遇到方法重载时优先匹配固定参数方法，其次再是可变长参数 其本质上还是基于数组实现，可变长参数编译之后会转换成一个数组 拷贝 前置说明 值传递：接收实参的拷贝，即创建副本，对形参修改不影响实参 引用传递： 接收实参所引用的对象在堆中的地址，不会创建副本，对形参修改影响实参 在Java中，是只有值传递的 引用拷贝: 就是把一个引用数据类型的值复制一下，给一个新的引用数据类型，它俩指向的对象的地址是一样的。 注：因为在Java中引用数据类型存储的就是对象地址值，所以传值就把引用复制了一下，本质上就是值传递。这里区别于C++中的&amp;，把一个变量的地址作为参数传过去，传的不是实参的值，是其地址 对象拷贝 创建一个新对象，地址不一样 浅拷贝： 针对原始对象中的成员变量进行值传递和引用拷贝，所以如果改变复制对象或者原始对象中的引用类型变量，会同时影响对方。 一般使用默认的clone()方法即可 深拷贝： 对原始对象中的基本数据类型变量进行值传递，但是对引用数据类型变量进行空间申请和此变量指向的对象复制，即对整个原始对象进行拷贝，产生一个独立的新对象。 可以借助重写clone()方法或者通过对象序列化(Serializable)实现 另外，由深拷贝性质可知，如果引用数据类型成员变量用final修饰深拷贝将失败，没法儿重新赋值 hashCode()和equals() 之前一直以为但凡重写了equals()就必须重写hashCode()，但是实际上不是的： 在不创建类对应的散列表(Hashset``HashMap等等)时，两者无关； 反之则确实需要重写，散列表中高效查找及去重会用到(定位链表/数组索引位置) String 字符存储 Java9之前使用char[]，从其开始使用byte[]： 1private final byte[] value; 新版的 String 其实支持两个编码方案：Latin-1 和 UTF-16。 如果字符串中包含的汉字没有超过 Latin-1 可表示范围内的字符，那就会使用 Latin-1 作为编码方案。 Latin-1 编码方案下，byte 占 1 个字节(8 位)，char 占用 2 个字节（16），byte 相较 char 节省一半的内存空间。 JDK 官方就说了绝大部分字符串对象只包含 Latin-1 可表示的字符。 如果字符串中包含的汉字超过 Latin-1 可表示范围内的字符，byte 和 char 所占用的空间是一样的 Sting不可变的理解： 保存字符串的数组被final修饰且为私有，同时String类没有提供或暴露修改这个字符串的方法 String类本身被final修饰无法被继承，避免子类破坏 StringBuilder和StringBuffer： 都继承自AbstracStringBuilder，其没有使用final和private关键字，同时提供很多修改字符串的方法 StringBuffer对方法或者调用的方法加了同步锁，线程安全；而StringBuilder则没有，是非线程安全 相同情况下StringBuilder比StringBuffer性能稍高 JDK9之前String字符串+拼接借助StringBuilder调用append()，之后改为动态方法makeConcatWithConstants() 拼接优化可以研究一下 String.itern() 其作用是对字符串常量池进行数据修改或者查找 JDK7之前字符串常量池放在永久代，其中存储对象。所以itern()方法会先去看字符串常量池里有没有这个对象，没有就创建；有就返回 JDK7开始字符串常量池迁移到堆中，存储引用。因此itern()会在字符串常量池查找引用，没有的话就创建一个指向堆区对应的已有字符串对象地址的引用；有则返回引用 常量折叠(Constant Folding) 编译过程中，Javac编译器会进行常量折叠代码优化： 常量折叠会把常量表达式的值求出来作为常量嵌在最终生成的代码中，这是 Javac 编译器会对源代码做的极少量优化措施之一(代码优化几乎都在即时编译器中进行)。 对于 String str3 = “str” + “ing”; 编译器会给你优化成 String str3 = “string”; 并不是所有的常量都会进行折叠，只有编译器在程序编译期就可以确定值的常量才可以： 1.基本数据类型( byte、boolean、short、char、int、float、long、double)以及字符串常量。 2.final 修饰的基本数据类型和字符串变量 3.字符串通过 “+”拼接得到的字符串、基本数据类型之间算数运算（加减乘除）、基本数据类型的位运算（&lt;&lt;、&gt;&gt;、&gt;&gt;&gt; ） 泛型 注意： 静态方法中无法访问类的泛型成员变量(因为静态方法加载先于类的实例化)，需要用到的话可以在静态方法上声明、使用自己的泛型参数，与类的泛型参数无关 序列化与反序列化 概念 序列化： 将数据结构或对象转换成二进制字节流的过程 反序列化： 将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程 序列化协议对应TCP/IP模型应用层的表示层 使用 对于Java自带的序列化方式，只需实现java.io.Serializable接口或者Externalizable接口。这里主要记录/针对前者 serialVersionUID： 序列化号serialVersionUID属于版本控制的作用。 反序列化时，会检查serialVersionUID是否和当前类的serialVersionUID一致。 如果serialVersionUID不一致则会抛出InvalidClassException异常。 强烈推荐每个序列化类都手动指定其serialVersionUID，如果不手动指定，那么编译器会动态生成默认的serialVersionUID 显式指定serialVersionUID是在类中使用static和final关键字修饰一个long类型变量，变量名为serialVersionUID 某些字段不进行序列化 可以使用transient关键字修饰不想进行序列化的变量： 对象实例中被transient修饰的变量序列化会被阻止，反序列化时变量值不会持久化、恢复 transient只能修饰变量，不能修饰类和方法 transient修饰的变量反序列化后其值会被设置为该类型的默认值 被static修饰的变量，存在于方法区，无论有无transient修饰都不会被序列化。(serialVersionUID比较特殊，作为一致性标识，在对象实例序列化时其也会被序列化到二进制字节流，反序列化时会一并解析并做一致性判断。)","categories":[{"name":"Java","slug":"Java","permalink":"http://711lxsky.github.io/categories/Java/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Linux(1)","slug":"blog16","date":"2023-12-23T01:22:00.000Z","updated":"2023-12-23T01:22:00.000Z","comments":true,"path":"2023/12/23/blog16/","link":"","permalink":"http://711lxsky.github.io/2023/12/23/blog16/","excerpt":"","text":"Linux小记 记录一些针对于Linux的操作指令，服务器/开发机等 服务器上CentOS的一些指令 防火墙 使用系统指令 1234567systemctl start firewalld #开启systemctl stop firewalld #关闭systemctl restart firewalld #重启systemctl reload firewalld #重新加载systemctl status firewalld #查看状态systemctl enable firewalld #设置开机自启动systemctl disable firewalld #取消开机自启动 使用firewall-cmd指令 123456789firewall-cmd --state #查看状态firewall-cmd --reload #重新加载firewall-cmd --add-port=80/tcp --permanent #永久添加端口firewall-cmd --list-ports #查看端口firewall-cmd --list-all #查看所有规则firewall-cmd --list-services #查看所有服务firewall-cmd --add-service=http #添加服务firewall-cmd --add-service=http --permanent #永久添加服务firewall-cmd --remove-service=http #删除服务 记录一些ubuntu22.04上的操作 美化操作 更新 12sudo apt updatesudo apt upgrade 安装相关依赖软件 12sudo apt install gnome-tweaks chrome-gnome-shellsudo apt install gnome-shell-extensions 美化 去到Firefox或者Chrome中下载gnome插件，然后下载对应的美化包、执行操作。这玩意儿装的扩展可以在系统菜单下的扩展里找到打开 flameshot安装使用 安装 1sudo apt-get install flameshot 设置快捷键 使用指令flameshot gui即可对屏幕进行截取，一般在设置中增加自定义快捷键F1，将其与截屏指令绑定 对于aria2的安装使用 aria2的github仓库 基本 安装 1sudo apt-get install aria2 配置 1234mkdir /etc/aria2 #新建文件夹 touch /etc/aria2/aria2.session #新建session文件chmod 777 /etc/aria2/aria2.session #设置aria2.session可写 vim /etc/aria2/aria2.conf #创建配置文件 这是aria2.conf文件对应内容，具体配置可更改： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153## 全局设置 ## ============================================================# 日志#log-level=warn#log=/PATH/.aria2/aria2.log # 后台运行#daemon=true # 下载位置, 默认: 当前启动位置dir=/home/Aria2/Downloads/ # 从会话文件中读取下载任务 都用绝对路径input-file=/etc/aria2/aria2.session # 在Aria2退出时保存`错误/未完成`的下载任务到会话文件save-session=/etc/aria2/aria2.session # 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0save-session-interval=30 # 断点续传continue=true # 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M#disk-cache=32M # 文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc# 预分配所需时间: none &lt; falloc ? trunc &lt; prealloc# falloc和trunc则需要文件系统和内核支持# NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项file-allocation=none# 客户端伪装user-agent=netdisk;5.2.6;PC;PC-Windows;6.2.9200;WindowsBaiduYunGuanJiareferer=http://pan.baidu.com/disk/home # 禁用IPv6, 默认:falsedisable-ipv6=true # 其他always-resume=truecheck-integrity=true ## 下载位置 ## ============================================================# 最大同时下载任务数, 运行时可修改, 默认:5max-concurrent-downloads=10 # 同一服务器连接数, 添加时可指定, 默认:1max-connection-per-server=10 # 最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M# 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载min-split-size=10M # 单个任务最大线程数, 添加时可指定, 默认:5split=5 # 整体下载速度限制, 运行时可修改, 默认:0#max-overall-download-limit=0 # 单个任务下载速度限制, 默认:0#max-download-limit=0 # 整体上传速度限制, 运行时可修改, 默认:0#max-overall-upload-limit=0 # 单个任务上传速度限制, 默认:0#max-upload-limit=0 ## RPC设置 ## ============================================================# 启用RPC, 默认:falseenable-rpc=true # 允许所有来源, 默认:falserpc-allow-origin-all=true # 允许非外部访问, 默认:falserpc-listen-all=true # 事件轮询方式, 取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同#event-poll=select # RPC监听端口, 端口被占用时可以修改, 默认:6800rpc-listen-port=6800 # 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项#rpc-secret=&lt;TOKEN&gt; # 是否启用 RPC 服务的 SSL/TLS 加密,# 启用加密后 RPC 服务需要使用 https 或者 wss 协议连接#rpc-secure=true # 在 RPC 服务中启用 SSL/TLS 加密时的证书文件,# 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥#rpc-certificate=/path/to/certificate.pem # 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件#rpc-private-key=/path/to/certificate.key ## BT/PT下载相关 ## ============================================================# 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true#follow-torrent=true # BT监听端口, 当端口被屏蔽时使用, 默认:6881-6999listen-port=51413 # 单个种子最大连接数, 默认:55#bt-max-peers=55 # 打开DHT功能, PT需要禁用, 默认:trueenable-dht=false # 打开IPv6 DHT功能, PT需要禁用#enable-dht6=false # DHT网络监听端口, 默认:6881-6999#dht-listen-port=6881-6999 dht-file-path=/opt/var/aria2/dht.datdht-file-path6=/opt/var/aria2/dht6.dat # 本地节点查找, PT需要禁用, 默认:false#bt-enable-lpd=false # 种子交换, PT需要禁用, 默认:trueenable-peer-exchange=false # 每个种子限速, 对少种的PT很有用, 默认:50K#bt-request-peer-speed-limit=50K # 设置 peer id 前缀peer-id-prefix=-TR2770- # 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0seed-ratio=0 # 强制保存会话, 即使任务已经完成, 默认:false# 较新的版本开启后会在任务完成后依然保留.aria2文件#force-save=false # BT校验相关, 默认:true#bt-hash-check-seed=true # 继续之前的BT任务时, 无需再次校验, 默认:falsebt-seed-unverified=true # 保存磁力链接元数据为种子文件(.torrent文件), 默认:falsebt-save-metadata=true bt-max-open-files=16 # Http/FTP 相关connect-timeout=120 启动aria2 1aria2c --conf-path=/etc/aria2/aria2.conf 使用 在可以正常启动的情况下，可以开启后台启动（终端不会显示进程日志） 1aria2c --conf-path=/etc/aria2/aria2.conf -D 接下来选择使用web端或者客户端gui形式对下载任务、配置来可视化操作，前者在浏览器中下载“Aria2下载器集成组件”，后者可在aria2的安装路径下使用命令行启动 可选 设置aria2开机启动 新建启动脚本 12345678910111213141516171819202122232425262728#!/bin/sh### BEGIN INIT INFO# Provides: aria2# Required-Start: $remote_fs $network# Required-Stop: $remote_fs $network# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Aria2 Downloader### END INIT INFO case &quot;$1&quot; instart) echo -n &quot;已开启Aria2c&quot; sudo aria2c --conf-path=/etc/aria2/aria2.conf -D;;stop) echo -n &quot;已关闭Aria2c&quot; killall aria2c;;restart) killall aria2c sudo aria2c --conf-path=/etc/aria2/aria2.conf -D;;esacexit 修改文件权限（a+x） 1sudo chmod 755 /etc/init.d/aria2c 添加开机启动服务 1sudo update-rc.d aria2c defaults 启动 1sudo service aria2c start 可查看服务状态 1sudo systemclt status aria2c 安装搜狗输入法 搜狗官方安装文档 更新 1sudo apt update 安装fcitx 1sudo apt install fcitx 然后可以使用优化或者命令行使得fcitx可以开机自启动 安装搜狗输入法 去到搜狗输入法官网下载对应版本, –&gt; 官网，然后解压安装 安装 12sudo apt install libqt5qml5 libqt5quick5 libqt5quickwidgets5 qml-module-qtquick2sudo apt install libgsettings-qt1 重启之后就能看到Fcitx对应的输入法了，再对其稍稍配置 卸载默认的ibus输入法框架（可选） 1sudo apt purge ibus 针对firefox无法打开简书 地址栏输入about:config，接受风险进入 上方搜索栏查找general.useragent.overrride，未找到则新建字符串，填入Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/119.0 ，后续即可访问","categories":[{"name":"Linux","slug":"Linux","permalink":"http://711lxsky.github.io/categories/Linux/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Mybatis-Plus(2)","slug":"blog15","date":"2023-12-23T01:00:00.000Z","updated":"2023-12-23T01:00:00.000Z","comments":true,"path":"2023/12/23/blog15/","link":"","permalink":"http://711lxsky.github.io/2023/12/23/blog15/","excerpt":"","text":"Mybatis-plus小记 记录些小坑小点 @TableField 注解里的内容和表字段名对应，标了这个注解就必须一摸一样捏… 要不然查不到 命名问题 表中字段名如果是以 _ 来分隔，则实体类成员变量名使用驼峰命名法，比如user表中有个 user_id 字段，那么实体类 User 中就是 userId 否则使用查询语句时会映射不到，导致明明有数据却查出来为 null 构造器的in 使用wrapper（条件构造器）时，可以传List； 比如说有个 List ，里面放的是userId，我现在想构造一个能一次性把这些 id 对应的 user 全查出来的 wrapper ，是不能写 eq 的，用 eq 会和 List 这个对象比较；而用 in 的话，在确保字段和 List元素一致的情况是可以的。 另外有个解决方法是放在循环中，或者在自定义语句中配置 in 对应的 foreach @TableLogic 逻辑删除的配置和使用不要忘记： application.yml中配置:123456mybatis-plus: global-config: db-config: logic-delete-field: #&#123;全局逻辑删除实体字段名&#125; logic-delete-value: #&#123;逻辑已删除值，默认为1&#125; logic-not-delete-value: #&#123;逻辑未删除值，默认为0&#125; 实体类上加上@TableLogic注解 @TableId 此注解加在实体类对应数据库主键的字段上，其包含属性value和type: 1@TableId(value = &quot;#&#123;主键名称&#125;&quot;, type = TdType.#&#123;枚举类型&#125;) 一般用自增逻辑type = IdType.AUTO","categories":[{"name":"SQL","slug":"SQL","permalink":"http://711lxsky.github.io/categories/SQL/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Mysql(2)","slug":"blog14","date":"2023-12-23T00:30:00.000Z","updated":"2023-12-23T00:30:00.000Z","comments":true,"path":"2023/12/23/blog14/","link":"","permalink":"http://711lxsky.github.io/2023/12/23/blog14/","excerpt":"","text":"Mysql小记 外键约束 设置主从表主键、外键（主键所在为主表，外键所在为从表）的时候，注意外键约束属性 CASCADE : 父表delete/updatate时，子表同步delete/update关联记录 SET NULL : 父表delete/update, 子表将关联记录的关键字段所在列设为null， 因此设计子表时外键不能设为not null RESTRICT : 如果子表中有关联父表的记录，那么想要删除父表记录时会不允许 NO ACTION : 同RESTRICT，子表有匹配记录就不允许父表update/delete 但是，目前其实很多场景不需要数据库中的真实外键，只用设计逻辑外键就行 真实外键存在的情况下： 一是不方便数据测试 二是高并发造成死锁 三是一致性事务完全交给数据库处理，很多时候资源占用高 关键词查询/模糊匹配 涉及关键字查询或者模糊匹配的时候可以用 通配符模糊匹配、内置函数检索、正则匹配查询、全文索引 通配符有 % _ 加上like操作符 内置函数有 instr() locate() position() 等，语法接近 mysql 支持绝大部分正则表达式功能，基于 regexp/rlike 等，基本涵盖所有需求 全文索引是mysql索引中的一种，支持字段格式包括char、varchar、text，语法为match(#&#123;字段名&#125;) against(#&#123;keyWord&#125;)。若不存在任何匹配结果，返回0；否则根据匹配次数多少和位置先后返回一个匹配度。 布尔值 true, false, 1 , 0 mysql中没有内置布尔类型，使用tinyint(1)来作为其等效进行存储，同时提供boolean和bool作为tinyint(1)的同义词。0被认为是false，非零值被认为true。而默认使用true和false时，计算值为1和0 NULL值与字符串空值 一般来说，''空值说的是字符串是空的，也就是个空串；而NULL值的是一个字段未知，即unkonwn,两者不能混为一谈 特别注意，针对于NULL值是有特殊的处理运算符的：IS NULL, IS NOT NULL，所以用=、!=、&gt;、&lt;是不行的； 但是有一个特例：&lt;=&gt;运算，形如exp &lt;=&gt; NULL，如果exp的值是NULL，会返回1 另外，有一些针对NULL的函数： IFNULL(exp): 如果exp的值为NULL，则返回1，否则返回0 IFNULL(exp1, exp2): 如果exp1是NULL的话那么返回exp2的值，否则返回exp1的值 NULLIF(exp3, exp4)：如果exp3 = exp4成立，那么返回NULL值，否则返回exp1值 去重 一般常用的去重方法有distinct和group by distinct: 用于select语句开头 如果去重列具有NULL值，会保留一个NULL值并删除其他 多列去重的条件下，只有所有指定列的的列信息都相同才会认为此信息重复 group by`： 通常和聚合函数如count()、max()等一起使用，放在where条件之后 可以单列/多列去重(mysql5.7之后默认SQL模式包括ONLY_FULL_GROUP_BY，默认要求使用group by时去重列即查询列。可以打破，重新设置) 去重的时候，group by会根据去重字段分组，如果数据相同那么就会分到一个组里面，再返回每个组的第一条数据，完成去重 效率的话，mysql8.0之前group by有个隐式排序： 在Mysql8.0之前,Group by会默认根据作用字段（Group by的后接字段）对结果进行排序。在能利用索引的情况下，Group by不需要额外进行排序操作；但当无法利用索引排序时，Mysql优化器就不得不选择通过使用临时表然后再排序的方式来实现GROUP BY了。且当结果集的大小超出系统设置临时表大小时，Mysql会将临时表数据copy到磁盘上面再进行操作，语句的执行效率会变得极低。这也是Mysql选择将此操作（隐式排序）弃用的原因。 所以，从8.0开始，在语义相同，不论有无索引的情况下二者效率相同； 在8.0之前，如果没有索引，group by会进行隐式排序，触发filesort，效率低 另外： 有的场景需要针对去重之后的数据作统计，可以使用count()函数，以去重字段为计数条件 连接查询 一般连接查询的语法: 1select column from table1 #&#123;连接方式&#125; table2 on #&#123;连接条件&#125; 内连接inner join 这种方式是提取两张表的共同点，即交集；且是系统默认的连接方式，可以省略inner 左连接left join 此方式查询左表table1的的全部内容以及右表table2中符合条件的记录，如果table2中有些字段没有匹配到会默认使用NULL补充代替 右连接right join 同理，查询右表table2的全部内容和左表table1符合条件记录，NULL补充未匹配上字段 连接查询后面时常还会加另外的限制条件，where、having等 using关键字 连接查询时可以用on作为连接条件，同样也可以用using，两者效果一致： using(#&#123;某个字段&#125;) = on table1.#&#123;同名字段&#125; = talbe2.#&#123;同名字段&#125; 注意： using关键字针对的是同名字段 使用using之后在拼接表中会自动合并对应字段为一个 using支持同时使用多个字段 count()函数 条件计数的话里面经常和别的函数一起用，比方说if，针对某个字段的某个条件计数可以写成： 1count(if($&#123;condition&#125;, 1, null)) 这样写的原因是：coount()只要该行有值就会统计，null才不计","categories":[{"name":"SQL","slug":"SQL","permalink":"http://711lxsky.github.io/categories/SQL/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Spring-Boot注意点(1)","slug":"blog13","date":"2023-12-23T00:11:00.000Z","updated":"2023-12-23T00:11:00.000Z","comments":true,"path":"2023/12/23/blog13/","link":"","permalink":"http://711lxsky.github.io/2023/12/23/blog13/","excerpt":"","text":"记录SpringBoot使用时的一些小坑大雷 返回结果类Result要有get set方法 否则会报错： HttpMediaTypeNotAcceptableException 或者前端调用接口会返回 406 状态码 即客户端无法解析服务端内容 错误原因： 客户端请求期望与服务器响应的媒体类型不一致，一般都是用json格式（控制器使用@RestController注解）；如果Result类没有get set方法会在对象转换成json时出问题 不要忘记扫描/注入mapper 有时使用自动生成的代码可能没有@Mapper注解，这可能会导致项目启动失败 解决: 在mapper.java类加上注解@Mapper 或者在启动类上标注@MapperScan($&#123;path&#125;),path是mapper.java类的所在目录（目的是扫描到所需类） @RequestBody注解不能用在Get方法中 其实这个算网络的知识点，Get请求的参数是通过url方法传递而不是请求体，所以无法用@RequestBody注解接收 解决： 将请求方法转换为Post 使用多个RequestParam接受后拼装成对象 使用@ModelAttribute注解 使用JSON格式接收数据，再转化为对象 对于依赖循环 这个太容易发生了，特别是架构设计没规划好的时候，写着写着就报错了 解决 使用@Lazy注解，对一个Bean进行延时加载。注入代理，使用时才被完全初始化 Setter/Field注入，实际上依赖没有被注入，只有需要时才被注入 @Autowired注解将required属性设置为false 等等，不止这些 其实真正合理且符合架构设计准则的是重构，解耦规划 对于依赖循环的底层下次可以好好唠唠","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://711lxsky.github.io/categories/SpringBoot/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Java概念(1)","slug":"blog12","date":"2023-12-22T23:30:00.000Z","updated":"2023-12-22T23:30:00.000Z","comments":true,"path":"2023/12/22/blog12/","link":"","permalink":"http://711lxsky.github.io/2023/12/22/blog12/","excerpt":"","text":"Java笔记概念篇 Java Edition Java SE (Java Platform, Stadard Edition): Java平台标准版，Java的基础部分（通常学校所教、一般所称的Java语言），包含程序开发、运行所需核心类库以及虚拟机等核心组件。可用于构建桌面应用程序、简单服务器程序。 最基本的语言环境 Java EE (Java Platform, Enterprise Edition): Java平台企业版，在Java SE基础之上建立而来，包含企业级应用程序和部署的标准、规范。早前的Servlet、JSP、JDBC等等。Java EE 可用于构建分布式、可移植、健壮、可伸缩、安全的服务端Java应用程序。 大概就是单单一个Java SE是没法满足企业开发需要，配套标准之后方便与其他应用程序联合开发（数据库、各种中间件） Java ME (Java Platform, Micro Edition)： Java的微型版本，主要用于开发嵌入式应用程序。 很早的一个东西，我记得Sun公司刚开始就是往这方面做，现在基本无了（ C++, C这些比Java更适合） JVM、JIT、JRE、JDK JVM (Java Virtual Machine) Java 虚拟机，用以运行Java字节码，是一个利用软件技术虚构出来的计算机，也是一种规范 Java程序运行的过程：源文件(.java) -&gt; 编译器 -&gt; 字节码(.class) -&gt; 解释器 -&gt; 机器码 JVM类加载器加载字节码文件，然后解释器逐行解释生成机器码，机器码交给系统之后，系统会与硬件交互完成工作。而解释器这一步就是由JVM调配执行，JVM针对不同系统进行解释器不同的实现，使得相同字节码在不同系统下运行出相同结果 JVM具体细节日后再补充 JIT (Just In Time Compilation) 运行时编译，是一种技术，一般在JVM中使用。其在完成第一次编译后，会将字节码对应的机器码保存，以便下次直接使用(部分方法或代码块运行频繁，JIT就会把这部分“热点代码”编译成本地机器对应的机器码，并缓存。JVM会根据代码执行情况收集信息并相应给出优化) JRE (Java Runtime Environment) Java运行时环境，是运行已编译Java程序所需所有内容的集合，包含Java虚拟机(JVM)、Java基础类库(Java Class Library) JDK (Java Development Kit) Java开发工具包，能够创建和编译Java程序，包含JRE以及一些其他工具比如jdb（调试器）、javadoc（文档注释工具）等 JVM-JRE-JDK三者关系： 注： Java9引入模块化和jlink，可以使用jlink打包一个程序运行时映像，只需要打包所需的特定包，借此来提供运行时环境并且减少内存和消耗","categories":[{"name":"Java","slug":"Java","permalink":"http://711lxsky.github.io/categories/Java/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Java+Go-代码应用(1)","slug":"blog11","date":"2023-12-22T23:11:00.000Z","updated":"2023-12-22T23:11:00.000Z","comments":true,"path":"2023/12/22/blog11/","link":"","permalink":"http://711lxsky.github.io/2023/12/22/blog11/","excerpt":"","text":"Java和Go具体代码的使用 Java之List去重 有时业务场景需要针对一个 List 中的数据进行去重 如果是根据类对象去重可能还好，甚至不用重写 hashCode()方法和 equals()方法； 但是如果对对象中某个成员变量去重，就稍显麻烦，这时候可以借助 java8 的特性来去重 例如下语句，实现 users列表 中针对 name属性 去重，得到新的不含 name重复项 的 deleteRepeatUsers 列表 1234567List&lt;Problem&gt; deleteRepeatUsers = users.stream().collect( Collectors.collectingAndThen( Collectors.toCollection( () -&gt; new TreeSet&lt;&gt;( Comparator.comparing(User::getName))), ArrayList::new) ); 其中： .stream() 将 users 转换为一个流，后续使用流操作处理 .collect() 和 .Collectors.toCollection() 都用于将流中元素收集到一个集合(Collection)中，后者返回一个收集器(Collect) Collectors.collectingAndThen()包装另一个收集器，用于在使用其他收集器收集数据后对产生一个最终的结果（中转站） () -&gt; new TreeSet&lt;&gt;(Comparator.comparing(User::getName))是一个Lambda表达式，表示一个无参构造函数的引用：创建一个新的TreeSet对象，并传递一个Comparator，通过User:getName方法引用定义排序（过滤）规则 综上，users转换成流收集后，数据经过TreeSet去重再转换回ArrayList容器 Go之make()函数 make(type, len, cap) type : 数据类型 len : 实际占用空间 cap : 预留空间 内存分配： 先是只会去用len的空间，如果空间不够，再去拿cap的空间，这样避免了二次内存分配，提高效率。如果cap的空间或者在未指定cap的情况下len的空间满了，就会再进行动态内存分配策略，再去申请当前内存的相同空间，于是内存变为两倍","categories":[{"name":"Code","slug":"Code","permalink":"http://711lxsky.github.io/categories/Code/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"Docker小记(1)","slug":"blog10","date":"2023-12-22T17:35:00.000Z","updated":"2023-12-22T17:35:00.000Z","comments":true,"path":"2023/12/22/blog10/","link":"","permalink":"http://711lxsky.github.io/2023/12/22/blog10/","excerpt":"","text":"docker速查小手册 记录一些docker常用指令 查看镜像 1sudo docker images 查看容器 1sudo docker ps -a 进入正在运行的容器 1sudo docker exec -it $&#123;容器id&#125; bash 提交容器修改，保存为镜像 1sudo docker commit $(容器id) $&#123;仓库名&#125;:$&#123;版本号&#125; 删除镜像 1sudo docker rmi $&#123;镜像id(可只取前3字符)&#125; 停止/启动容器 1sudo docker start/stop $&#123;容器id(可3字符)&#125; 删除容器（停止容器之后） 1sudo docker rm $&#123;容器id(可3字符)&#125; 查看容器详细信息 1sudo docker inspect $&#123;容器id(可3字符)&#125; 查看容器日志 1sudo docker logs $&#123;容器id(可3字符)&#125; 进入容器 1sudo docker exec -it $&#123;容器id(可3字符)&#125; /bin/bash 导出、导入 12sudo docker save -o $&#123;导出路径/文件名及后缀(.tar.gz)&#125; $&#123;需要导出的镜像ID(可3字符)&#125;sudo docker load -i $&#123;导入路径/文件名及后缀(.tar.gz)&#125; 或 12sudo docker export $&#123;需要导出的容器id(可3字符)&#125; &gt; $&#123;导出路径/文件名及后缀(.tar)&#125;sudo docker import $&#123;导入路径/文件名及后缀(.tar)&#125; $&#123;镜像名&#125; 两种方式区别： 首先，export命令是从容器(container)中导出tar文件，而save命令是从镜像(image)中导出 文件大小不同：export导出的镜像文件小于save保存的镜像 是否支持对镜像重命名： import命令可以为镜像指定新名称 load命令不能对载入镜像重命名 是否支持将多个镜像打包到一个文件： export不支持 save支持 是否包含镜像历史： export导出(import导入)是根据容器拿到的镜像，再导入时会丢失镜像所有的历史记录和元数据信息，即其仅保存容器当时的快照状态，所以无法进行回滚操作 save保存(load加载)的镜像，没有丢失镜像的历史，可以回滚到之前的层(layer) 应用场景： export主要用来制作基础镜像，作为开发的基础环境 save是将用到的镜像打包，然后拷贝到不能连接外网的服务器上并用load 容器之间互相复制文件 1sudo docker cp $&#123;容器id(可3字符)&#125;:$&#123;容器内路径&#125; $&#123;目标容器id(可3字符)&#125;:$&#123;目标容器内路径&#125; 基于当前容器创建镜像 1sudo docker commit -a &quot;作者信息&quot; -m &quot;描述信息&quot; $&#123;容器id(可3字符)&#125; $&#123;镜像名:$&#123;版本号&#125;&#125; docker run 用于根据指定的镜像创建和启动一个新的容器， 基本语法： 1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 执行流程： 第一步，在指定镜像上创建一个可写的容器层 第二步，使用指定命令(COMMAND)启动 简而言之，docker run相当于执行两个API: /containers/create、/containers/(id)/start OPTIONS说明： -i，以交互模式运行容器，通常与 -t 同时使用 -t，启动容器后，为容器分配一个命令行，通常与 -i 同时使用 -v，目录映射，容器目录挂载到宿主机目录，格式： &lt;宿主机目录&gt;:&lt;容器目录&gt; -d，守护进程，后台运行该容器 -p，指定端口映射，格式：主机(宿主)端口:容器端口-P，随机端口映射，容器内部端口随机映射到主机的端口 -u，以什么用户身份创建容器--name &quot;容器名字&quot; -m, --memory bytes，设置容器使用内存最大值 -h, --hostname string，指定容器的宿主机名 --dns指定容器 dns 服务器 -e 设置环境变量 --restart，Docker重启后，容器是否自动重启 --privileged，容器内是否使用真正的root权限 很多指令随用随查即可，也可以直接加--help查看帮助信息","categories":[{"name":"Docker","slug":"Docker","permalink":"http://711lxsky.github.io/categories/Docker/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"算法小记(1)","slug":"blog9","date":"2023-12-22T11:01:00.000Z","updated":"2023-12-22T11:01:00.000Z","comments":true,"path":"2023/12/22/blog9/","link":"","permalink":"http://711lxsky.github.io/2023/12/22/blog9/","excerpt":"","text":"算法小笔记 背景(闲话) 好久没更了，这不到年底了。想想马上2024了，干脆把之前的东西整理整理吧 向上取整技巧 $x \\div y$ 一般来说，刚开始都会想到两种方法： 1res = x % y == 0 ? x / y : x / y + 1; 或者 1res = Math.ceil(x / y); 实际上，第一种还行，但是稍显啰嗦；第二种容易出bug，而且调用消耗高。 有更简单的： 1res = (x + y - 1 ) / y 简单证一下： 假设 : $x \\div y = a \\cdots b$, 那么: $x = a \\cdot y + b$, 则 $(x + y - 1 ) \\div y$ $= (a \\cdot y + y + b - 1 ) \\div y $ $= a + (y + b - 1) \\div y$ 如果 $b = 0 $， 那么后半部分就是 $0$ 了; 如果 $b \\geq 1 $， 也就是不能整除，$a$ 就会 $+ 1$; 二分板子 nnd, 今天每日一题有思路，知道拿二分，也肯定能过但是居然卡二分实现这儿了 12345678910111213141516171819202122232425/** * nums为查找范围(升序排列)， target即目标 * 现在查找nums数组中大于等于target的第一个数的下标 */pubulic int dichotomy(int [] nums , int target)&#123; int n = nums.length; int left = 0 , right = n - 1; int resLabel = -1; while(left &lt;= right)&#123; /* 循环条件注意 = ，即某一个位置需要判断是否符合*/ int mid = left + (right - left) / 2; /* 注意防溢出，也可以写成： int mid = left + (right - left &gt;&gt; 1) 注意移位运算符的优先级*/ if(nums[mid] &gt;= target)&#123; resLabel = mid; right = mid - 1; &#125; else &#123; left = mid + 1; &#125; /* 有时候也根据需要直接把 mid 赋给 left/right */ &#125; return resLabel;&#125; 我之前老想不清的是找到第一个满足条件的数，需要借助前一次查找的标记。但是实际上，在窗口移动的过程中，范围一直在缩小、寻找满足条件且最靠前的数，缩到最小(到达最优解)后下次就会不满足条件直接跳出了。 求解最短路 1. floyd(弗洛伊德算法) floyd算法是把一个图里边的各个点之间的最短路都算出来，适合多源最短路问题 就是每拿到一个点，就借助这个点建立其他点之间的联系，更新其他点之间的最短路 朴素floyd实现： 12345678910111213141516171819202122232425262728293031 /** * 弗洛伊德算法朴素式，借助矩阵实现 * 给定一个 n 节点的图， * 且参数包含边权矩阵 edges[][]，其内层大小为 3 , 分别表示 起点，终点，路径长度 */public int [][] floydSimplicity(int n, int[][] edges)&#123; // 建立并初始化距离矩阵 int[][] dis = new int[n][n]; for(int i = 0 ; i &lt; n ; i ++)&#123; Arrays.fill(dis[i], Integer.MAX_VALUE / 2); &#125; // 将距离加入 for(int [] edge : edges)&#123; int from = edge[0], to = edge[1], len = edge[2]; dis[from][to] = len; dis[to][from] = len; &#125; // 三层遍历得到所有点之间的最短路 for(int k = 0 ; k &lt; n ; k ++)&#123; dis[k][k] = 0; for(int i = 0 ; i &lt; n ; i ++)&#123; for(int j = 0 ; j &lt; n ; j ++)&#123; dis[i][j] = Math.min(dis[i][j], dis[i][k] + dis[k][j]); &#125; &#125; &#125; return dis;&#125; 2. dijkstra(迪杰斯特拉算法) dijkstra算法是从一个点出发，不断更新此点到其他点的最短路，直到所有点都到达或者遍历完。适合单源最短路问题，但同样也可用于多源 12345678910111213141516171819202122232425262728293031323334353637383940414243 // 下面先针对多源最短路问题给出dijkstra朴素实现，条件同上public int [][] dijkstraSimplicity(int n, int[][] edges)&#123; // 建立并初始化距离矩阵和路径矩阵 int[][] dis = new int[n][n]; int[][] map = new int[n][n]; // 创建访问矩阵，标记某个位置是否作为最近点使用过 boolean[][] vis = new boolean[n][n]; for(int i = 0 ; i &lt; n ; i ++)&#123; Arrays.fill(dis[i], Integer.MAX_VALUE / 2); Arrays.fill(map[i], Integer.MAX_VALUE / 2); &#125; // 将边权加到路径矩阵中，方便后续直接使用 for(int [] edge : edges)&#123; int from = edge[0], to = edge[1], len = edge[2]; map[from][to] = len; map[from][to] = to; &#125; for(int i = 0 ; i &lt; n ; i ++)&#123; dis[i][i] = 0; // 每个点到自身距离为0 for(int j = 0 ; j &lt; n ; j ++)&#123; int shortPos = -1; // 寻找最近的点 for(int k = 0 ; k &lt; n ; k ++)&#123; if( !vis[i][k] &amp;&amp; (shortPos == -1 || dis[i][k] &lt; dis[i][shortPos]))&#123; shortPos = k; &#125; &#125; vis[i][shortPos] = true; // 借助最近点去算到其他点的距离，不断更新 for(int k = 0 ; k &lt; n ; k ++)&#123; dis[i][k] = Math.min(dis[i][k], dis[i][shortPos] + map[shortPos][k]); &#125; &#125; &#125; return dis;&#125;","categories":[{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://711lxsky.github.io/categories/Arithmetic/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://711lxsky.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"记一次失败的双周赛","slug":"blog8","date":"2023-11-12T20:20:00.000Z","updated":"2023-11-12T20:20:00.000Z","comments":true,"path":"2023/11/12/blog8/","link":"","permalink":"http://711lxsky.github.io/2023/11/12/blog8/","excerpt":"","text":"赛后 让我唠唠 这次的双周赛，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很菜，我是真的很 谢谢，上面这是AI给我写的。不过也是实话，giao , byd😡还挺懂我是吧 昨天，双十一，秋风萧瑟，哥们儿一个人搁寝室独自力扣单排双周赛。第二题坐牢。 啊，平常卡三四也理解，第二想着怎么优化就是不行(不排除是白天xdoj写多了降智) 来题： 给小朋友们分糖果II 正文 当时因为放在第二题，数据规模比第一题要高，所以我估摸着直接开第二题，弄完再开三四，好家伙，直接给我卡这儿了 第一题 先来水一下 链接： 给小朋友们分糖果I 数据规模很小，所以实际上可以双层for直接暴力过 123456789101112131415class Solution &#123; public int distributeCandies(int n, int limit) &#123; int res = 0; for(int num1 = 0 ; num1 &lt;= limit ; num1 ++)&#123; for(int num2 = 0 ; num3 &lt;= limit ; num3 ++)&#123; if(n - num1 - num2 &gt;= 0 &amp;&amp; n - num1 - num2 &lt;= limit)&#123; res ++; &#125; // 没啥好说的，只需要三个人的数据都在 0~limit 之间即可 &#125; &#125; &#125; return res;&#125; 第二题 我的想法 kid : 小朋友 candy : 糖果数量 因为是给3个小家伙分，所以考虑的情况是很少的，我就想着首先kid1拿，然后kid2，再是kid3，所以初始状态就是： 123int candy1 = Math.min(n, limit);int candy2 = Math.min(n - candy1, limit);int candy3 = Math.min(n - candy1 - candy2, limit); 现在起始状态有的，肯定是 $ candy1 \\geq candy2 \\geq candy3$，所以我想的维持这个状态，这样只需要看这三个糖果数是哪种情况： $ a, a, a $ $ a, a, b $ 或者 $ a, b, b $ $ a, b, c $ 可以假想成各个情况下，糖果的分法 第一种情况，那么就是$A_3^0 = 1$ 第二种，$A_3^1 = 3$ 第三种，$A_3^2 = 6$ 写一个方法或者函数来判断当前处于哪种情况，然后累加即可 但是，它这个分配策略太繁琐了，有 candy1 -&gt; candy2 candy1 -&gt; candy3 candy2 -&gt; candy3 调了很久没想明白(应该有dp的思想)，加上交了几发都错了，就寄啦😝 学来的(对，我就是剽窃智慧doge) 每次赛后都习惯看看榜前面的Java代码，然后给自己一巴掌复盘 其实可以这样想： 首先，$ candy1 $从$ 0 $开始迭代，终止条件为$ \\leq limit $ 和 $\\leq n$， 然后剩下的先给$ candy2 $， 如果$ candy2 \\leq limit $ ，那这种策略下分配方式是$ candy2 + 1 $ 如果$ candy2 &gt; limit $，那就令$ candy2 = limit $，然后剩下的再减去$limit$，再给$ candy3 $这种策略下分配方式是$ limit - candy3 + 1 $ 关于分配方式，这里只需要看$ candy2 $ 和 $ candy3 $，二者在满足条件的情况下分配方式是$ candy2 - candy3 + 1 $ 所以代码可以这样： 123456789101112131415161718192021222324class Solution &#123; public long distributeCandies(int n, int limit) &#123; long res = 0; for(int num1 = 0 ; num1 &lt;= limit &amp;&amp; num1 &lt;= n; num1 ++)&#123; int rest1 = n - num1; if(rest1 &lt;= limit)&#123; res += rest1 + 1; &#125; else &#123; //int num2 = limit ; /** * 这里把num2 直接省掉了， * 因为num2 已经被赋值为limit了， * 所以这里直接用limit 即可 */ int num3 = rest1 - limit; if(num3 &lt;= limit)&#123; res += limit - num3 + 1; &#125; &#125; &#125; return res; &#125;&#125; 挺好理解的，就是按常规的枚举来的实际上。用不着看糖果数来算方案。 ε=(´ο｀*)))唉，每次都是第二题想复杂，不需要其实。 还有，下次写公式记得在front-matter里开一下mathjax，还为这找了会儿bug😠","categories":[{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://711lxsky.github.io/categories/Arithmetic/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://711lxsky.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"(除草水文)回顾and计划","slug":"blog7","date":"2023-10-16T18:00:00.000Z","updated":"2023-10-16T18:00:00.000Z","comments":true,"path":"2023/10/16/blog7/","link":"","permalink":"http://711lxsky.github.io/2023/10/16/blog7/","excerpt":"","text":"一个多月想了很多 真是快捏，翻开博客才发现原来已经一个多月没有更了😓，中间修过几次小bug，但是一直没有好好沉下来写写文章 想想啊，这个月，XDU-Inspur纳新、新项目接手、给小家伙写文档，还有骤然增加的课程，唉，比暑假可挤占时间多了(那时候还能熬熬夜，现在修修bug第二天都头疼的不行 😇) 再有呢，陆陆续续关注秋招，观察老东西们的出路，我也在思考自己的规划，之前好像慢慢的就是往开发这方面靠，虽然写的大项目不多，但是感觉这方面还是比较适合自己。大一进来想着保研，然后就被高数当头一棒，索性一狠心来计科逼自己一把好好学技术（当然，以前也是想来这儿的）。科研、研究生的氛围着实不是很痴迷（虽然家里人总是喊着读个研😥），相反，自己学一些感兴趣的技术、算法or小玩意儿倒是更好玩儿。但这毕竟是吃饭的家伙什，关系到未来的生活捏，所以技术要精进往深了挖。 回首 想想啊，目前会的： 语言方面：C,C++,Python,JavaScript,Java，其中C基本所有语法都用过，而且算比较熟悉（毕竟就那么些东西）；C++的话类这块儿比较薄弱的，自己去专门做一个demo好像比较少，一般都是写题调个STL；Python的话帮别人写过一个大作业、跟着书写过一个本地小游戏；Js的话之前学前端学过，但是挺浅的（html、css随用随查了）；Java就老伙计了，常用语法是熟悉的😋 框架：SpringBoot+Mybatis-plus+Vue，主要还是后端，毕竟本行了 数据库：Mysql+Redis，感觉都是只会用，做crud这些😭 算法方面：基本数据结构都了解的，图和树做的少，别的都有，力扣180题（池子也挺浅的）+其他平台的一些题，周赛常年两题选手 操作系统：最近实验室装了个ubuntu玩玩儿(玩儿熟了自己也装一个)，手里还有两台服务器（私人+Inspur），也差不多指令是即用即搜，bash脚本没有系统去学 giao，这么一列发现没会多少，而且还比较浅，不少都是会用，底层原理这些就不懂了(恼)😑 以后 既然确实打算走这条路了，那就踏踏实实走下去，也确实需要大大滴😀踏实沉淀： Java的并发编程、反射机制，集合源码，IO流深入的东西，还有jvm的实现、调优 继续学习Spring这一套框架，SpringCloud、SpringSecurity这些碰的不多，还得研究研究底层逻辑，最好去读读源码，自己做做扩展 数据库这块儿沉到底下去学学 分布式这一块儿的学习需要提上日程了，可以适当在项目中加入 计网好好学，操作系统很重要，计组也是 继续练算法，尽量每日一题+周赛，剑指offer和hot100刷完；适量打一打算法竞赛 项目的话，最后投实习就选出一个轮子+一个业务放简历上 总结一下，就是项目+八股+算法 最后 不要懈怠或者浪费不必要的时间😠 八股笔记整理整理正好可以发发blog就当水文了 嗯…还要综合学校文化课、实验、社团等等杂七杂八的东西，还得注意注意身体，越来越肥宅力 保持开心捏😊","categories":[{"name":"Life","slug":"Life","permalink":"http://711lxsky.github.io/categories/Life/"}],"tags":[{"name":"想法","slug":"想法","permalink":"http://711lxsky.github.io/tags/%E6%83%B3%E6%B3%95/"}]},{"title":"准大二军训期间的遐想","slug":"blog6","date":"2023-09-02T22:00:55.000Z","updated":"2023-09-02T22:00:55.000Z","comments":true,"path":"2023/09/02/blog6/","link":"","permalink":"http://711lxsky.github.io/2023/09/02/blog6/","excerpt":"","text":"一些杂想during军训 想想啊，从上次更算法之后，基本在vue的学习和leetcode刷题中度过，然后觉得之前博客的主题过于花里胡哨，想弄得简介点儿，于是花了两天时间重新配置和部署，再之后貌似就军训了？？？ 唉，去年没训留到了现在 军训嘛，自然身体上的锻炼更多，至于思绪，可以随意飞扬飘到哪儿就是哪儿… 在酷日的暴晒之下，静静琢磨琢磨两道算法题，也有更多时间和心境想想这些和那些（虽然很多时候也会烦躁和无奈） 也许是反省和鞭挞？自己也常干这事儿… change mind😇 我觉得自己以前，至少初高中时期，是个把苦难磨砺当成阶梯的人。每次身边人都在抱怨埋汰的时候，自己都是默默忍受和服从，像孙少平一样接受苦难、享受苦难。 军训之前，我也觉得不就是累点儿吗，站会儿有什么大不了的。被训的时候我也是这样想着，喉咙痛着着了凉也是继续训着。但是经过xiao ling dao某些人的一系列不合理措施打击之后，好像更多的是无奈失望。😰我开始想这些东西的合理存在性，以及我对待其的态度想法。 逆来顺受不是对的；能吃苦是对的；存在不一定合理，也不一定不合理；自己到底有没有认真思考过当下、以前这些苦难的意义？ 我自己也没有清楚的定义，但是我想我应该想的多，像章北海，要多想。我觉得苦难本身对我的定义应该是一种正反馈机制，死撑是不是一种感动自己？考虑效益最大化是最终目的吗？ cultivate personality😌 不记得何时起社恐成为我逃避某些场合的最正当理由，也不记得何时起某些瞬间会有外表相当内敛和内心的张狂糅合成一个矛盾体，冷漠自私与热烈感性也是我。 从小到大，好像有好多时候感叹做这个事儿的为什么不是我，我明明可以做的更好。可是我又清楚知道机会不偏向怯懦者。 无数个时刻痛恨Ta的丑恶嘴脸和行为的同时自己转头却坐着同样的事；向君子品格看齐却永远调不过来。 想的不够，做的不够；随性的同时应该是不失竹兰之风的；冷静不能以失去善良为代价。还要学的有很多捏 control spirit😆 理性不够，头脑貌似越来越不理智而是跟着感觉和情绪走。从很小很小的时候起，哥们儿就希望自己能够好好地控制自己的情绪。似乎现在越走越远。。。 军训静坐的时候，平心静气的那种感觉也好久没有体会到了。 做感兴趣的事儿固然有趣，但是不喜欢的事儿自己好像越来越不能让自己去尝试，社交、人际、接触，好多好多… look forward😐 有些事儿总是埋在心头，不知道是阴影还是回忆。自己不去揭，但好像某些时刻会自动冒出来，我不停的告诫自己都是过去式，仰望以后吧。 也不算多坏吧，自己一手造就不能怨谁。 现在也不算太烂吧，至少哥们儿没有陷太久。 陆陆续续遇到很好的人啦，同龄，年长，更幼，或并肩或教导或领携，睡一觉什么都能过去。 keep avtive😋 不做悲观主义者，尽管自己知道脑子里应该是乐观主义占优，但悲观主义总是冒头出来捣乱，加剧内耗和焦虑 保持热爱和善良，不尽纯粹，但有清明 少emo啦，小事情啦~~ 多笑笑捏 over😴 翻翻上面，好像不知道写了啥，又好像都写了，有点儿零表涕零，不知所言那味儿？ 睡力~~~","categories":[{"name":"Life","slug":"Life","permalink":"http://711lxsky.github.io/categories/Life/"}],"tags":[{"name":"想法","slug":"想法","permalink":"http://711lxsky.github.io/tags/%E6%83%B3%E6%B3%95/"}]},{"title":"我眼中的KMP算法","slug":"blog5","date":"2023-08-17T14:20:13.000Z","updated":"2023-08-17T14:20:13.000Z","comments":true,"path":"2023/08/17/blog5/","link":"","permalink":"http://711lxsky.github.io/2023/08/17/blog5/","excerpt":"","text":"KMP算法小解 水背景😜 很早就想更一更题解，力扣也好，洛谷也好，写写题，记录一下思路和算法，想想就很爽😇 陆陆续续碰到过不少难题（对我而言）和马叉虫的题（不难但是思想特别好、需要一定脑回路的） 正文 KMP碰到过不少次，最早应该是在XD教学oj上做字符串的题，再后来是力扣，洛谷貌似也遇到过？当时暴力能过，看了看KMP的题解，头都大了（猪脑过载🐷），大致看了半懂就扔收藏夹吃灰辽 最近翻出来，热热还能吃琢磨看看 目前力扣是主战场，所以就贴一下那边原题罢：找到字符串中第一个匹配项的下标，本文也对标此题 虽然标的难度是简单 ，但是应该是指暴力解法，KMP方法还是需要好好想想的😪 暴力解法 虽然平平无奇，还是写写分析对比一下（doge） 1234567891011121314151617181920212223242526/* haystack 为主串 needle 为模式串 如果找到匹配项，return 主串匹配处的第一个字符下标; 否则 return -1*/class Solution &#123; public int strStr(String haystack, String needle) &#123; int i = 0 , j = 0 , lenH = haystack.length(), lenN = needle.length(); while(i + lenN &lt;= lenH)&#123; while(j &lt; lenN)&#123; if(haystack.charAt(i + j) != needle.charAt(j))&#123; break; &#125; j ++; &#125; if(j == lenN)&#123; return i; &#125; i ++; j = 0; &#125; return -1; &#125;&#125; 我们的目标很简单，找到匹配下标，所以每次未匹配成功的话直接 break ，同时索引 j 都会再次回到 0 位置。 😬这样的时间复杂度是O(lenH*lenN)，和KMP比起来是相当差的： KMP解法 我们其实可以发现，在暴力解法中，虽然索引 i 表面上看起来没有动，但是实际上起比较作用的是 i + j 和 j , i 只是匹配失败后回溯到了 i + 1 位置而已。相当于： 123456789101112131415161718192021class Solution &#123; public int strStr(String haystack, String needle) &#123; int i = 0 , j = 0 , lenH = haystack.length(), lenN = needle.length(); while(i &lt; lenH &amp;&amp; j &lt; lenN)&#123; if(haystack.charAt(i) == needle.charAt(j))&#123; i ++; j ++; &#125; else &#123; i = i - j + 1; j = 0; &#125; &#125; if(j == lenN)&#123; return i - j; &#125; return -1; &#125;&#125; 回溯后的比较其实有很多是之前已经比过的，而这些地方恰恰是我们要利用的😆 Knuth-Morris-Pratt 算法，简称KMP算法，其消除了主串索引 i 的回溯，从而提高匹配效率。 在KMP算法中，i 是不能回退的，我们借助的是将 j 回退一定的步数。问题是应该回退多少步？理想情况下回退后要保证 i 左侧的字符和 j 左侧的字符能够匹配，这个时候就需要我们的前缀数组 next [] 了 求解前缀数组 next [] 一点前置知识： 前缀： 从串首到某个位置i结束的一个子串，即s[0…i] 真前缀：除完整串s之外的前缀部分，相当于不看最后一个字符得到的前缀 后缀：从某个位置开始到串尾结束的子串，即s[i…|s|-1] 真后缀：同理喽，除s外的后缀，相当于不看第一个字符 最长公共真前后缀：顾名思义，就是真前后缀里边都有，而且最长的那条子串 比如对于串 example = “nice” 有： 前缀： n, ni, nic, nice 真前缀： n, ni, nic 后缀： e, ce, ice, nice 真后缀： e, ce, ice 最长公共真前后缀： 为空 对于KMP算法我们需要关注模式串needle的最长真前后缀 给出一个 int 数组 next [] ，其大小与needle长度相等，其元素 next[t] = k 是对于子串 s[0:t-1] 的最长公共真前后缀长度 k ，即 s[0:k-1] = s[p-k:p-1]，k 也叫做失效长度，同时也就是 j 需要回退到的位置（根据最长公共真前后缀的性质，回退之后 i 和 j 左侧是完全匹配的，符合我们的要求）😮 求解思想 首先next[0] = -1 ，因为 0 - 1 = -1 ，已经超过最小索引无法再移动了，这相当于一个标志（所以将 -1 改为其他负数也行） 其次next[1] = 0 , 因为对于单个字符的子串，其真前后缀为空串，长度为 0 需要两个索引，p(position) 和 v(value), 分别用来记录子串右侧字符位置和子串对应的最长公共真前后缀长度。同时将 p 初始化为0，v 初始化为 next[0] 对应值 当 needle.charAt(p) == needle.charAt(v)时，表示最长公共真前后缀可以加长，所以next[ ++p ] = ++ v; 如果 needle.charAt(p) != needle.charAt(v)，现在前后缀对不上，那么 v 就需要往前找更短的最长公共真前后缀，又是回溯！注意我们现在拿着的正是 next [] ！！！所以不需要返回串首，直接 v = next[v]，这里相当重要😎 综上，v 有可能回到 next[0] ，所以当 v = next[0] 时，进行 v = 0 ; next[ ++p ] = 0; 对上述思想中的4进行验证 我们假设已知 next[p] (p &gt; 1) == k , 即 needle[0:k-1] == needle[p-k:p-1] 如果 needle[k] == needle[p] ，那么就有 needle[0:k] == needle[p-k:p], 即 next[p+1] = k + 1 ，与思想4符合 至于5的话，我没有找到/想到特别恰当的文字描述，感觉抽象地说也好理解😝 求解代码 将上述思想转化成代码实现： 123456789101112131415161718public int [] getNext(String needle)&#123; int lenN = needle.length(); int [] next = new int [lenN]; next[0] = -1222; int p = 0 , v = next[0]; while(p &lt; lenN - 1)&#123; if(v == next[0])&#123; next[++p] = v = 0; &#125; else if(needle.charAt(p) == needle.charAt(v))&#123; next[++p] = ++v; &#125; else &#123; v = next[v]; &#125; &#125; return next; &#125; 如果将next[0] 设为 -1，代码会更简洁：😆 123456789101112131415public int [] getNext(String needle)&#123; int lenN = needle.length(); int [] next = new int [lenN]; int p = 0 , v = -1; next[p] = v; while(p &lt; lenN - 1)&#123; if(v == -1 || needle.charAt(p) == needle.charAt(v))&#123; next[ ++p ] = ++ v ; &#125; else &#123; v = next[v] ; &#125; &#125; return next; &#125; 到这里基本上已经完成主要工作了，但是还不够： 实际跑的过程中，next 数组还会有一点缺陷，比如： haystack = “aaaabcc” , needle = “aaaac” 根据之前的思路，int [] next = {-1, 0, 1, 2, 3} ； 注意：当 i 走到 4 ，j 走到 4 时 haystack.charAt(i) = ‘b’ 与 needle.charAt(j) = ‘c’ 首次匹配失败，那么 j 回退到 next[4] 即 3 , needle.charAt(j) = ‘a’ ，再次匹配失败，再次回退，结果还是’a’，还是需要回退，这样也会增加时间消耗。最理想的情况就是一下子直接回退成功，跳过中间元素重复的位置。 可以想到，因为 haystack 与 needle 匹配失败的时候有 j = next[j], 而 next[] 由 v 更新而来，我们需要跳过匹配失败的元素，所以重源头修改，当检查到元素重复我们直接跳到 next[v]： 1234567891011121314151617181920public int [] getNext(String needle)&#123; int lenN = needle.length(); int [] next = new int [lenN]; int p = 0 , v = -1; next[p] = v; while(p &lt; lenN - 1)&#123; if(v == -1 || needle.charAt(p) == needle.charAt(v))&#123; if(needle.charAt( ++p ) == needle.charAt( ++ v))&#123; next[p] = next[v]; &#125; else &#123; next[p] = v; &#125; &#125; else &#123; v = next[v] ; &#125; &#125; return next; &#125; 修改算法之后求得的 next [] = {-1, -1, -1, -1, 3}，符合预期效果😀 完整代码 哦了，next [] 数组算完了，整体代码也就完工了： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public int strStr(String haystack, String needle) &#123; int i = 0 , j = 0 , lenH = haystack.length(), lenN = needle.length(); // 获取 next [] int [] next= getNext(needle); while( i &lt; lenH &amp;&amp; j &lt; lenN)&#123; if( j == -1 || haystack.charAt(i) == needle.charAt(j))&#123; i ++; j ++; &#125; else &#123; // 匹配失败，回退 j = next[j]; &#125; &#125; if(j == lenN)&#123; return i - j; &#125; return -1; &#125; public int [] getNext(String needle)&#123; int lenN = needle.length(); int [] next = new int [lenN]; int p = 0 , v = -1; next[p] = v; while(p &lt; lenN - 1)&#123; if(v == -1 || needle.charAt(p) == needle.charAt(v))&#123; if(needle.charAt( ++p ) == needle.charAt( ++ v))&#123; next[p] = next[v]; &#125; else &#123; next[p] = v; &#125; &#125; else &#123; v = next[v] ; &#125; &#125; return next; &#125;&#125; 这次的时间复杂度是O(lenH + lenN)了，空间复杂度会略有增加😋","categories":[{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://711lxsky.github.io/categories/Arithmetic/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://711lxsky.github.io/tags/%E7%AE%97%E6%B3%95/"}],"author":"耳易"},{"title":"聊聊Bootstrap(BS)","slug":"blog4","date":"2023-07-31T17:23:52.000Z","updated":"2023-07-31T17:23:52.000Z","comments":true,"path":"2023/07/31/blog4/","link":"","permalink":"http://711lxsky.github.io/2023/07/31/blog4/","excerpt":"","text":"瞎扯一扯我眼中的Bootstrap 力扣写不下去力（晕），来写写博客划划水理一理脑子 日常水背景 最近在弄浪潮这边静态网页的设计和美化： 感谢Bootstrap这种对我这样的菜鸡后端er极其友好的框架，整体写的还算顺利，除了博客这块儿采用的mkdocs外，剩下都是靠的BS（救！） 所以写写自己的浅显认知罢，理一理坑和小tips 正片开始 首先，依然坚持我的观点，官方文档是最好的学习资料和手册 扔： Bootstrap官方 民间大神翻译站 平常要用到的啥随时CV查用即可 日常使用引入 框架使用官方讲的很清楚，用CDN可以，下载源文件也可以 注： CDN即内容分发网络( Content Delivery Network )，采用缓存服务器并将其放在用户相对集中的地区或网络，用户访问时，利用全局负载技术，将访问指向最近的缓存服务器上响应请求（类似电商本地仓库）采用CDN可以大大提升访问速度、提升安全性等 对于Bootstrap来讲，使用者的CSS和JS配置文件都写好了放在不远的地方，引入一下，相当于直接从云端扒下来使用 所以，开发者使用时只需要专注HTML文件，考虑布局、细节即可，需要的组件都已经写好了 Bootstrap官方也说：&quot; HTML和CSS优于JS &quot;，所以站在这个角度俺觉得它更像个组件库 还是说说具体用法，这里也有注意点来着，写写罢，怕自己也忘了 1.使用CDN CSS引入： 1&lt;link href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD&quot; crossorigin=&quot;anonymous&quot;&gt; JavaScript引入： 1&lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js&quot; integrity=&quot;sha384-/mhDoLbDldZc3qpsJHpLogda//BVZbgYuw6kof4u2FrCedxOtgRZDTHgHUhOCVim&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; 属性说明： href 和 src 很明显嘛，html里常用的，用以资源指向定位 rel 也很常见，定义链接资源和当前文档关系 剩下这俩可能就比较少见了，一般都是在用CDN引入第三方库的时候碰到，intergrity 用以开启浏览器对获取的资源进行检验(借助hash值查验文件是否经过篡改)，比如此处就是使用sha384算法对下载的文件进行计算并和intergrtiy提供的摘要签名比对；crossorigin定义元素如何处理跨源请求，实现对该元素获取数据的CORS(跨源资源共享，一种基于HTTP头的机制)请求配置。（此处其实两者实现机制和逻辑都比较复杂） 2.直接下载 这个就比较简单粗暴了，当然，官方为了让开发者自定义功能，也提供了生产文件和源码两种模式，后者稍麻烦，一般来讲Bootstrap已经把功能实现的可以了，拿来用就行 下载解压文件夹后，选出bootstrap.min.css和bootstrap.bundle.min.js就行，涵盖绝大部分需要了 一些使用tips 趁还记得，先写上（笑） 网格and列布局 这个相当好用，很容易作出简介整齐的布局 响应断点：xs、sm、md、lg、xl、xxl ， 对应尺寸：576px、768px、960px、1200px、1400px 一行12格，各列分配，放不下就跑下一行 .row-cols-可以直接指定一行的列数，不用在各个.col上写 卡片 其实我觉得卡片只是把元素边框明显化了的块区域，用div(一把梭选手就是我)也能实现差不多的效果 和列结合，设计出水平变化的卡片 .card-group实现卡片群组，自动对齐（这个也有点儿列表的意思） .h-设置高度，用以同行卡片对齐美观 位置 这玩意儿有时候特别容易出bug .align-items-和.align-self-指定垂直对齐，控制水平排布;.justify-content-指定水平对齐，控制垂直排布 .flex弹性盒子结合上者可以特殊设置元素位置，排版方便 .start-、.end-、.top-、.bottom-、.translate-middle可以强制指定位置 其他 常使用.d–none 和 .d–block结合控制特定尺寸下元素的显示方式 轮播结合长宽比比较好看 模态弹框、滑动导航可以把大量文本隐藏，点击后显示，方便布局 工具提示可以放在链接、按钮上增加交互 貌似就这些我觉得比较好用的（当然，前端菜狗后端也是） 小结 反正给我带的感觉吧，Bootstrap适合做一些比较小型或者页面简单的静态站，做起来真挺方便，而且部署直接一丢就行（当然，别的框架打包也是相当方便的） 鱼摸完了，溜~~","categories":[{"name":"Frontend","slug":"Frontend","permalink":"http://711lxsky.github.io/categories/Frontend/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}],"author":"耳易"},{"title":"关于Mybatis-Plus(1)","slug":"blog3","date":"2023-07-15T21:00:00.000Z","updated":"2023-07-15T21:00:00.000Z","comments":true,"path":"2023/07/15/blog3/","link":"","permalink":"http://711lxsky.github.io/2023/07/15/blog3/","excerpt":"","text":"聊一聊关于mybatis-plus的日常开发 背景： 日常开发中，Dao层(Date Access Object)作为数据访问层，承载大量的数据交互处理，直接联系数据库，服务于业务逻辑 这里就不得不提到mybatis，一款非常优秀的持久层框架，直接免除传统JDBC代码，通过注解、xml配置数据对象映射即可实现数据CRUD(增删改查) 而mybatis-plus作为国产之光，由国人苞米豆团队在mybaits基础上进一步增强，上手更为快速 (小声，贴一下mybaitis和mybatis-plus官方文档：) =&gt;mybstis =&gt;mybatis-plus spring-boot项目中使用mybatis-plus(推荐IDEA为开发工具) 项目maven配置文件pom.xml中引入依赖: 12345678910111213141516171819 &lt;!-- mybatis-plus --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.5.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis-plus代码生成器 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.5.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- freemarker 代码生成器的模板，不要忘了引入--&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt;&lt;/dependency&gt; 我日常使用数据库即mysql，所以引入mysql依赖： 12345&lt;!-- mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;/dependency&gt; 在配置文件application.yml或application.properties中配置数据库连接： 12345spring: datasource: username: &quot;对应数据库用户名&quot; password: &quot;对应密码&quot; url: jdbc:mysql:///&quot;项目对应数据架构&quot; 在IDEA中写项目的话最好装一个mybatisX插件,写自定义sql的时候比较方便 日常使用 1. 代码生成器 这玩意儿用了一次就知道多方便了，自动生成四层： 注: 它是根据数据架构自动生成的实体类、控制层等等，一张表对应一个实体类 具体代码可以看mybatis-plus文档的 贴一张项目截图示例： 2.普通service层CRUD接口 mybatis-plus为开发者封装了不少可以直接调用的CRUD接口 Get Save Remove Update 均支持泛型，详见官方文档 3.条件构造器wrapper Wrapper: 条件构造抽象类，最顶端父类 AbstractWrapper: 用于查询条件封装 QueryWrapper: Entiry对象封装操作类 UpdateWrapper: update条件封装 AbstractLambdaWrapper: Lambda语法使用Wrapper统一处理解析 LambdaQueryWrapper: 使用Lambda语法查询 LambdaUpdateWrapper: Lambda语法更新 条件构造器根据sql语法转换了许多的函数，如eq,gt等，这个一搜就很多 注：日常使用时最多用的是QueryWrapper、UpadateWrapper、LambdaQueryWrapper，前者使用条件构造函数时可以使用lambda()方法将该条件转化为lambda语法，这个有时候需要注意 使用示例： 4.自定义sql mybatis-plus当然也是支持自定义sql语句的，可以使用@select，@update等注解(暂时没怎么用)或者在Mapper.xml中书写自定义方法 如： mapper.xml文件示例： mapper层对应文件示例: 注：在Mapper.xml中除了select可以指定返回值外，别的都不可以有 小结： mybatis-plus属实是生产力工具，极大简化开发步骤(spring也有功劳)，但是目前耳易老师写的项目还太少，还是很多地方没用到(冰山一角) 上述所有相关内容只是个人近期的一个小梳理，在脑海中留个印象(猪脑不好使)","categories":[{"name":"SQL","slug":"SQL","permalink":"http://711lxsky.github.io/categories/SQL/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}],"author":"耳易"},{"title":"Mysql（1）","slug":"blog2","date":"2023-07-04T22:00:00.000Z","updated":"2023-07-04T22:00:00.000Z","comments":true,"path":"2023/07/04/blog2/","link":"","permalink":"http://711lxsky.github.io/2023/07/04/blog2/","excerpt":"","text":"由web项目引发的对mysql建表时的思考和注意 背景 之前ISC这边接手了一个开发项目，做一个志愿活动服务平台，因为开发经验不够，拿到手建表只考虑了用户信息和角色信息的关联，猪脑过载没想到活动这块儿，可想而知，接口写着写着就发现写不下去，表得重写（悲） 建表过程 1. 角色分区 考虑到关系逻辑，我干脆把用户信息和角色信息绑定，直接把区分区分角色建表：volunteer、organizer、regulator三张角色表 然后每个角色有最基本的用户信息id（各表主键）,name（唯一键）,password（加密存储）,phone,email,avatar（存储存放头像文件的路径） 根据不同的角色再细化特性字段： volunteer设置了志愿积分、参与活动数目统计、参与活动的最大限制数量、志愿状态 建表语句： 123456789101112131415161718create table volunteer ( id int auto_increment primary key, name char(32) not null, password varchar(64) null, phone char(12) null, email varchar(32) null, avatar varchar(64) null, score int default 0 null, activity_count int default 0 null, activity_max int default 0 null comment &#x27;限制最大参与活动数&#x27;, status int default 0 not null, deleted int default 0 null, constraint volunteer_u unique (name) ) comment &#x27;志愿者表&#x27;; organizer比较特殊的是一个限制最大活动发布数 建表语句： 123456789101112131415 create table organizer( id int auto_increment primary key, name char(32) not null, password varchar(64) not null, phone char(12) not null, eamil varchar(32) null, avatar varchar(64) null, activity_max int default 0 null, deleted int default 0 null, constraint organizer_u unique (name)) comment &#x27;组织者表&#x27;; regulator的话有个等级字段（打算的是陆续开放冻结用户、删除用户权限） 建表： 123456789101112131415 create table regulator( id int auto_increment primary key, name char(32) null, password varchar(64) not null, phone char(12) not null, email varchar(32) null, avatar varchar(64) null, rate int default 1 null comment &#x27;管理等级&#x27;, deleted int default 0 null, constraint regulator_pk unique (name)) comment &#x27;管理者表&#x27; 注意： varchar和char的使用：varchar是可变长，char则是定长，存储时varchar省空间一点儿，但是查询效率不及char（数据量特别大时差距会明显一点儿），我这儿把name和phone设为char是后续要借助这俩字段来查重 字段deleted用于mybatis-plus的逻辑删除处理（即虚假删除），事务逻辑删除开启后，经过虚假删除的记录在数据库会继续存在，但是查询的时候是自动忽略的（所以不要以为账户注销就万事大吉辽）。 2.活动管理 活动表activity的建立及与organizer表的关联 按照日常对于志愿活动的理解，设置了这些字段：id（主键），name(唯一键，活动不重名是为了用户查看历史信息时不会混淆), theme, organizer_id, data_time, location, volunteer_min, volunteer_max, volunteer_current_number, status, description, deleted 建表： 123456789101112131415161718192021create table activity( id int auto_increment primary key, organizer_id int null, name char(64) null, theme varchar(32) null, data_time datetime null, location varchar(128) null, volunteer_min int default 0 null comment &#x27;所需最小的志愿者数量&#x27;, volunteer_max int null comment &#x27;所需志愿者最大数&#x27;, volunteer_current_number int default 0 not null, status int default 0 not null comment &#x27;活动状态&#x27;, description text null comment &#x27;活动描述&#x27;, deleted int default 0 null, constraint activity_u unique (name), constraint activity_organizer_fk foreign key (organizer_id) references organizer (id)); 注： 其中organizer_id是关联organizer表中id的外键，与organizer表做到数据统一 status字段表示活动状态，不同整数代表不同状态，比如准备中、召集中、进行中、已完成等 description属于text数据类型，长文本哈，我的预期是把活动描述的字数控制在400字以内，这样也不会造成太大的查询效率影响 当参与志愿者数位于目标区间之内时，活动方可正式进行 activity与volunteer之间的关联 其实刚开始我想的是在志愿者表里面直接设置一些列，比如10列来存放活动id，和活动表关联起来，但是细想觉得很浪费空间，而且没有好好利用mysql这种关系型数据库的设计模式 所以我就新建了一个关系表activity_volunteer_relation，用来记录志愿者对于活动的参与情况： 123456789101112create table activity_volunteer_relation( id int auto_increment primary key, activity_id int null, volunteer_id int null, constraint fk1 foreign key (activity_id) references activity (id), constraint fk2 foreign key (volunteer_id) references volunteer (id)) comment &#x27;记录志愿者参与活动情况&#x27;; 字段id为主键，activity_id是关联activity的外键字段，volunteer_id是关联volunteer的外键字段，这样后面查询的时候直接根据活动id和志愿者id就能把记录查询出来，也不用担心volunteer的活动数改变的问题 思考 关于数据表建表： 数据类型选择。根据空间和效率来看哪个数据类型更合适放在这条记录中，日后开发高并发、高性能的项目时这点肯定会很重要（比如这次的varchar和char） 灵活处理关系。当对象关系比较杂乱的时候，分离出类来（没错，就是面向对象设计中的类），这本身也和java的观念吻合，实体类这一层也是这个思想。从对象之间关系的角度来设计表（类似volunteer和activity) 雷点（可能是日后项目里面的坑）： 有的字段可能还是不够合理，比方说activity的name，实际上应该允许存在不同主题下存在同名活动（问题倒也不大） 还有一些字段可能需要加，比如volunteer的等级、organizer的等级、信誉等等，随着等级的提升来对活动数目限制进行更改（这个改倒是方便，也不算大坑） 结语 大致这些罢，SQL这边玩儿的还不多，命令行下手写语句还是很容易打错，可视化界面（尤其像DataGrip、IDEA这些大赞）下倒还好。 还有约束条件、手撸多表、分页查询也不熟，mysql的函数更是没用多少，耳易老师会慢慢水水字更，慢慢学","categories":[{"name":"SQL","slug":"SQL","permalink":"http://711lxsky.github.io/categories/SQL/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"}],"author":"耳易"},{"title":"闲谈","slug":"blog1","date":"2023-06-28T23:30:00.000Z","updated":"2023-06-28T23:30:00.000Z","comments":true,"path":"2023/06/28/blog1/","link":"","permalink":"http://711lxsky.github.io/2023/06/28/blog1/","excerpt":"","text":"关于编程生活的XDer杂谈 更新说明 ​ 其实很久之前就正式搭好了博客，但是碍于种种原因没有好好写东西。大致可能是： 学校bi事儿太多。自己忙不过来，挤不出时间。想想去年一路走过来，从高考暑假学完C语法，去刷些基础题（计蒜客）。到西电以来，一下子被高数、程设打个措手不及。一波一波的作业和安排，自己还得抽空学java，C++，还有浪潮这边Web开发的各项技能SQL，Spring，JavaScript…还是菜的一批，博客一时还真是没弄 技术不够。这确实是事实。早先在洛谷写题的时候经常卡着（现在也卡），甚至学校那破教学oj上的题也有过不了的（恼）。再就是看到学长们Web技术的精湛，想写点儿啥害怕有点儿嚣张班门弄斧。陆陆续续看了数据结构之后又转战力扣，一度被简单题完虐爆锤。想写点啥又好像确实技术臭 该写力 其实身边不少同龄人琢磨博客这玩意儿，他们似乎不在乎自身水平（起码比我强），凭着一股热忱和程序员码农特有的开源精神经常更博文 技术大概比以前精进了一丢丢罢，后端方向倒是会写几个接口，来点儿简单的算法题似乎也能应付。 本身有复盘批判自己又臭又旧代码的习惯，写博文那种娓娓道来的感觉类似于高中讲题的味儿（高中也一弱ji），能巩固点儿八股也好，巩固点儿代码能力也好，脑子不好多写罢 大学以来似乎人际局限更厉害（没有妹子社交），有时候想说点儿啥似乎机会也没有。高中旧情亦渐行渐远，那正好写写喜欢的东西罢","categories":[{"name":"Life","slug":"Life","permalink":"http://711lxsky.github.io/categories/Life/"}],"tags":[{"name":"想法","slug":"想法","permalink":"http://711lxsky.github.io/tags/%E6%83%B3%E6%B3%95/"}],"author":"耳易"},{"title":"first blog","slug":"hello-world","date":"2022-11-25T18:00:00.000Z","updated":"2022-11-25T18:00:00.000Z","comments":true,"path":"2022/11/25/hello-world/","link":"","permalink":"http://711lxsky.github.io/2022/11/25/hello-world/","excerpt":"","text":"这是第一次博客搭建成功时的默认页面 下面连接都是hexo（静态博客框架）的响应服务官网 留作纪念就不删辽 Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[{"name":"Test","slug":"Test","permalink":"http://711lxsky.github.io/categories/Test/"}],"tags":[{"name":"测试","slug":"测试","permalink":"http://711lxsky.github.io/tags/%E6%B5%8B%E8%AF%95/"}]}],"categories":[{"name":"Project","slug":"Project","permalink":"http://711lxsky.github.io/categories/Project/"},{"name":"Linux","slug":"Linux","permalink":"http://711lxsky.github.io/categories/Linux/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://711lxsky.github.io/categories/SpringBoot/"},{"name":"Arithmetic","slug":"Arithmetic","permalink":"http://711lxsky.github.io/categories/Arithmetic/"},{"name":"Java","slug":"Java","permalink":"http://711lxsky.github.io/categories/Java/"},{"name":"SQL","slug":"SQL","permalink":"http://711lxsky.github.io/categories/SQL/"},{"name":"Code","slug":"Code","permalink":"http://711lxsky.github.io/categories/Code/"},{"name":"Docker","slug":"Docker","permalink":"http://711lxsky.github.io/categories/Docker/"},{"name":"Life","slug":"Life","permalink":"http://711lxsky.github.io/categories/Life/"},{"name":"Frontend","slug":"Frontend","permalink":"http://711lxsky.github.io/categories/Frontend/"},{"name":"Test","slug":"Test","permalink":"http://711lxsky.github.io/categories/Test/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://711lxsky.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"算法","slug":"算法","permalink":"http://711lxsky.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"想法","slug":"想法","permalink":"http://711lxsky.github.io/tags/%E6%83%B3%E6%B3%95/"},{"name":"测试","slug":"测试","permalink":"http://711lxsky.github.io/tags/%E6%B5%8B%E8%AF%95/"}]}